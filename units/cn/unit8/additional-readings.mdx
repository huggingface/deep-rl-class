# 额外阅读材料 [[additional-readings]]

这些是**可选阅读材料**，如果你想深入了解可以参考。

## PPO详解

- [Towards Delivering a Coherent Self-Contained Explanation of Proximal Policy Optimization by Daniel Bick](https://fse.studenttheses.ub.rug.nl/25709/1/mAI_2021_BickD.pdf)
- [如何理解强化学习中的近端策略优化算法？](https://stackoverflow.com/questions/46422845/what-is-the-way-to-understand-proximal-policy-optimization-algorithm-in-rl)
- [深度强化学习基础系列，L4 TRPO和PPO by Pieter Abbeel](https://youtu.be/KjWF8VIMGiY)
- [OpenAI PPO博客文章](https://openai.com/blog/openai-baselines-ppo/)
- [Spinning Up RL PPO](https://spinningup.openai.com/en/latest/algorithms/ppo.html)
- [论文：近端策略优化算法](https://arxiv.org/abs/1707.06347)

## PPO实现细节

- [近端策略优化的37个实现细节](https://iclr-blog-track.github.io/2022/03/25/ppo-implementation-details/)
- [近端策略优化实现第1部分（共3部分）：11个核心实现细节](https://www.youtube.com/watch?v=MEt6rrxH8W4)

## 重要性采样

- [重要性采样解释](https://youtu.be/C3p2wI4RAi8)
