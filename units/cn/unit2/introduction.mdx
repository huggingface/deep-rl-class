# Q-Learning简介 [[introduction-q-learning]]

<img src="https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit3/thumbnail.jpg" alt="Unit 2 thumbnail" width="100%" />


在本课程的第一单元中，我们学习了强化学习(RL)、RL过程以及解决RL问题的不同方法。我们还**训练了我们的第一个智能体并将它们上传到了Hugging Face Hub。**

在本单元中，我们将**深入研究强化学习方法之一：基于价值的方法**，并学习我们的第一个RL算法：**Q-Learning。**

我们还将**从头实现我们的第一个RL智能体**，一个Q-Learning智能体，并在两个环境中训练它：

1. Frozen-Lake-v1（非滑动版本）：我们的智能体需要**从起始状态(S)到达目标状态(G)**，只能在冰冻的瓦片(F)上行走，并避开洞(H)。
2. 自动驾驶出租车：我们的智能体需要**学习如何在城市中导航**，以**将乘客从A点运送到B点。**


<img src="https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit3/envs.gif" alt="Environments"/>

具体来说，我们将：

- 学习**基于价值的方法**。
- 了解**蒙特卡洛方法和时序差分学习之间的区别**。
- 研究并实现**我们的第一个RL算法**：Q-Learning。

如果你想能够研究深度Q-Learning，这个单元是**基础性的**：深度Q-Learning是第一个玩Atari游戏并在其中一些游戏（打砖块、太空入侵者等）中超越人类水平的深度RL算法。

那么让我们开始吧！🚀
