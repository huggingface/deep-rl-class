# å®è·µç»ƒä¹  [[hands-on]]

      <CourseFloatingBanner classNames="absolute z-10 right-0 top-0"
      notebooks={[
        {label: "Google Colab", value: "https://colab.research.google.com/github/huggingface/deep-rl-class/blob/main/notebooks/unit2/unit2.ipynb"}
        ]}
        askForHelpUrl="http://hf.co/join/discord" />



ç°åœ¨æˆ‘ä»¬å·²ç»å­¦ä¹ äº†Q-Learningç®—æ³•ï¼Œè®©æˆ‘ä»¬ä»å¤´å¼€å§‹å®ç°å®ƒï¼Œå¹¶åœ¨ä¸¤ä¸ªç¯å¢ƒä¸­è®­ç»ƒæˆ‘ä»¬çš„Q-Learningæ™ºèƒ½ä½“ï¼š
1. [Frozen-Lake-v1ï¼ˆéæ»‘åŠ¨å’Œæ»‘åŠ¨ç‰ˆæœ¬ï¼‰](https://gymnasium.farama.org/environments/toy_text/frozen_lake/) â˜ƒï¸ï¼šæˆ‘ä»¬çš„æ™ºèƒ½ä½“éœ€è¦**ä»èµ·å§‹çŠ¶æ€(S)åˆ°è¾¾ç›®æ ‡çŠ¶æ€(G)**ï¼Œåªèƒ½åœ¨å†°å†»çš„ç“¦ç‰‡(F)ä¸Šè¡Œèµ°ï¼Œå¹¶é¿å¼€æ´(H)ã€‚
2. [è‡ªåŠ¨é©¾é©¶å‡ºç§Ÿè½¦](https://gymnasium.farama.org/environments/toy_text/taxi/) ğŸš– éœ€è¦**å­¦ä¹ å¦‚ä½•åœ¨åŸå¸‚ä¸­å¯¼èˆª**ï¼Œä»¥**å°†ä¹˜å®¢ä»Aç‚¹è¿é€åˆ°Bç‚¹**ã€‚

<img src="https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit3/envs.gif" alt="Environments"/>

é€šè¿‡[æ’è¡Œæ¦œ](https://huggingface.co/spaces/huggingface-projects/Deep-Reinforcement-Learning-Leaderboard)ï¼Œä½ å°†èƒ½å¤Ÿä¸å…¶ä»–åŒå­¦æ¯”è¾ƒä½ çš„ç»“æœï¼Œå¹¶äº¤æµæœ€ä½³å®è·µä»¥æé«˜ä½ çš„æ™ºèƒ½ä½“å¾—åˆ†ã€‚è°å°†èµ¢å¾—ç¬¬2å•å…ƒçš„æŒ‘æˆ˜ï¼Ÿ

ä¸ºäº†åœ¨[è®¤è¯æµç¨‹](https://huggingface.co/deep-rl-course/en/unit0/introduction#certification-process)ä¸­éªŒè¯è¿™ä¸ªå®è·µç»ƒä¹ ï¼Œä½ éœ€è¦å°†è®­ç»ƒå¥½çš„å‡ºç§Ÿè½¦æ¨¡å‹æ¨é€åˆ°Hubï¼Œå¹¶**è·å¾— >= 4.5çš„ç»“æœ**ã€‚

è¦æŸ¥æ‰¾ä½ çš„ç»“æœï¼Œè¯·å‰å¾€[æ’è¡Œæ¦œ](https://huggingface.co/spaces/huggingface-projects/Deep-Reinforcement-Learning-Leaderboard)å¹¶æ‰¾åˆ°ä½ çš„æ¨¡å‹ï¼Œ**ç»“æœ = å¹³å‡å¥–åŠ± - å¥–åŠ±çš„æ ‡å‡†å·®**

æœ‰å…³è®¤è¯æµç¨‹çš„æ›´å¤šä¿¡æ¯ï¼Œè¯·æŸ¥çœ‹æ­¤éƒ¨åˆ† ğŸ‘‰ https://huggingface.co/deep-rl-course/en/unit0/introduction#certification-process

ä½ å¯ä»¥åœ¨è¿™é‡ŒæŸ¥çœ‹ä½ çš„è¿›åº¦ ğŸ‘‰ https://huggingface.co/spaces/ThomasSimonini/Check-my-progress-Deep-RL-Course


**è¦å¼€å§‹å®è·µç»ƒä¹ ï¼Œè¯·ç‚¹å‡»"åœ¨Colabä¸­æ‰“å¼€"æŒ‰é’®** ğŸ‘‡ï¼š

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/huggingface/deep-rl-class/blob/master/notebooks/unit2/unit2.ipynb)


æˆ‘ä»¬å¼ºçƒˆ**å»ºè®®å­¦ç”Ÿä½¿ç”¨Google Colabè¿›è¡Œå®è·µç»ƒä¹ **ï¼Œè€Œä¸æ˜¯åœ¨ä¸ªäººç”µè„‘ä¸Šè¿è¡Œã€‚

é€šè¿‡ä½¿ç”¨Google Colabï¼Œ**ä½ å¯ä»¥ä¸“æ³¨äºå­¦ä¹ å’Œå®éªŒï¼Œè€Œä¸å¿…æ‹…å¿ƒè®¾ç½®ç¯å¢ƒçš„æŠ€æœ¯æ–¹é¢**ã€‚


# ç¬¬2å•å…ƒï¼šä½¿ç”¨FrozenLake-v1 â›„ å’ŒTaxi-v3 ğŸš• çš„Q-Learning

<img src="https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit3/thumbnail.jpg" alt="Unit 2 Thumbnail" />

åœ¨è¿™ä¸ªç¬”è®°æœ¬ä¸­ï¼Œ**ä½ å°†ä»å¤´å¼€å§‹ç¼–å†™ä½ çš„ç¬¬ä¸€ä¸ªå¼ºåŒ–å­¦ä¹ æ™ºèƒ½ä½“**ï¼Œä½¿ç”¨Q-Learningæ¥ç©FrozenLake â„ï¸ï¼Œä¸ç¤¾åŒºåˆ†äº«å®ƒï¼Œå¹¶å°è¯•ä¸åŒçš„é…ç½®ã€‚

â¬‡ï¸ è¿™é‡Œæ˜¯**ä½ åœ¨çŸ­çŸ­å‡ åˆ†é’Ÿå†…å°†è¦å®ç°çš„å†…å®¹**çš„ç¤ºä¾‹ã€‚ â¬‡ï¸


<img src="https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit3/envs.gif" alt="Environments"/>

### ğŸ® ç¯å¢ƒï¼š

- [FrozenLake-v1](https://gymnasium.farama.org/environments/toy_text/frozen_lake/)
- [Taxi-v3](https://gymnasium.farama.org/environments/toy_text/taxi/)

### ğŸ“š RLåº“ï¼š

- Pythonå’ŒNumPy
- [Gymnasium](https://gymnasium.farama.org/)

æˆ‘ä»¬ä¸€ç›´åœ¨åŠªåŠ›æ”¹è¿›æˆ‘ä»¬çš„æ•™ç¨‹ï¼Œæ‰€ä»¥**å¦‚æœä½ åœ¨è¿™ä¸ªç¬”è®°æœ¬ä¸­å‘ç°ä»»ä½•é—®é¢˜**ï¼Œè¯·[åœ¨GitHubä»“åº“ä¸Šæå‡ºissue](https://github.com/huggingface/deep-rl-class/issues)ã€‚

## æœ¬ç¬”è®°æœ¬çš„ç›®æ ‡ ğŸ†

åœ¨å®Œæˆæœ¬ç¬”è®°æœ¬åï¼Œä½ å°†èƒ½å¤Ÿï¼š

- ä½¿ç”¨**Gymnasium**ï¼Œè¿™ä¸ªç¯å¢ƒåº“ã€‚
- ä»å¤´å¼€å§‹ç¼–å†™Q-Learningæ™ºèƒ½ä½“ã€‚
- **å°†ä½ è®­ç»ƒå¥½çš„æ™ºèƒ½ä½“å’Œä»£ç æ¨é€åˆ°Hub**ï¼Œé™„å¸¦ç²¾ç¾çš„è§†é¢‘å›æ”¾å’Œè¯„ä¼°åˆ†æ•° ğŸ”¥ã€‚

## æœ¬ç¬”è®°æœ¬æ¥è‡ªæ·±åº¦å¼ºåŒ–å­¦ä¹ è¯¾ç¨‹

<img src="https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/notebooks/deep-rl-course-illustration.jpg" alt="Deep RL Course illustration"/>

åœ¨è¿™ä¸ªå…è´¹è¯¾ç¨‹ä¸­ï¼Œä½ å°†ï¼š

- ğŸ“– **ç†è®ºå’Œå®è·µ**ç›¸ç»“åˆå­¦ä¹ æ·±åº¦å¼ºåŒ–å­¦ä¹ ã€‚
- ğŸ§‘â€ğŸ’» å­¦ä¹ **ä½¿ç”¨è‘—åçš„æ·±åº¦å¼ºåŒ–å­¦ä¹ åº“**ï¼Œå¦‚Stable Baselines3ã€RL Baselines3 Zooã€CleanRLå’ŒSample Factory 2.0ã€‚
- ğŸ¤– åœ¨**ç‹¬ç‰¹çš„ç¯å¢ƒä¸­è®­ç»ƒæ™ºèƒ½ä½“**

æ›´å¤šå†…å®¹è¯·æŸ¥çœ‹ ğŸ“š è¯¾ç¨‹å¤§çº² ğŸ‘‰ https://simoninithomas.github.io/deep-rl-course

ä¸è¦å¿˜è®°**<a href="http://eepurl.com/ic5ZUD">æ³¨å†Œè¯¾ç¨‹</a>**ï¼ˆæˆ‘ä»¬æ”¶é›†ä½ çš„ç”µå­é‚®ä»¶æ˜¯ä¸ºäº†èƒ½å¤Ÿ**åœ¨æ¯ä¸ªå•å…ƒå‘å¸ƒæ—¶å‘ä½ å‘é€é“¾æ¥ï¼Œå¹¶æä¾›æœ‰å…³æŒ‘æˆ˜å’Œæ›´æ–°çš„ä¿¡æ¯**ï¼‰ã€‚


ä¸æˆ‘ä»¬ä¿æŒè”ç³»çš„æœ€ä½³æ–¹å¼æ˜¯åŠ å…¥æˆ‘ä»¬çš„discordæœåŠ¡å™¨ï¼Œä¸ç¤¾åŒºå’Œæˆ‘ä»¬äº¤æµ ğŸ‘‰ğŸ» https://discord.gg/ydHrjt3WP5

## å…ˆå†³æ¡ä»¶ ğŸ—ï¸

åœ¨æ·±å…¥å­¦ä¹ æœ¬ç¬”è®°æœ¬ä¹‹å‰ï¼Œä½ éœ€è¦ï¼š

ğŸ”² ğŸ“š **é€šè¿‡[é˜…è¯»ç¬¬2å•å…ƒ](https://huggingface.co/deep-rl-course/unit2/introduction)å­¦ä¹ Q-Learning**  ğŸ¤—

## Q-Learningçš„ç®€è¦å›é¡¾

*Q-Learning* **æ˜¯ä¸€ç§å¼ºåŒ–å­¦ä¹ ç®—æ³•ï¼Œå®ƒ**ï¼š

- è®­ç»ƒ*Q-å‡½æ•°*ï¼Œè¿™æ˜¯ä¸€ä¸ª**åŠ¨ä½œ-ä»·å€¼å‡½æ•°**ï¼Œåœ¨å†…éƒ¨å­˜å‚¨ä¸­ç”±*Qè¡¨*ç¼–ç ï¼Œ**è¯¥è¡¨åŒ…å«æ‰€æœ‰çŠ¶æ€-åŠ¨ä½œå¯¹çš„å€¼**ã€‚

- ç»™å®šä¸€ä¸ªçŠ¶æ€å’ŒåŠ¨ä½œï¼Œæˆ‘ä»¬çš„Q-å‡½æ•°**å°†åœ¨Qè¡¨ä¸­æœç´¢ç›¸åº”çš„å€¼**ã€‚

<img src="https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit3/Q-function-2.jpg" alt="Q function"  width="100%"/>

- å½“è®­ç»ƒå®Œæˆåï¼Œ**æˆ‘ä»¬æœ‰ä¸€ä¸ªæœ€ä¼˜çš„Q-å‡½æ•°ï¼Œå› æ­¤æœ‰ä¸€ä¸ªæœ€ä¼˜çš„Qè¡¨**ã€‚

- å¦‚æœæˆ‘ä»¬**æœ‰ä¸€ä¸ªæœ€ä¼˜çš„Q-å‡½æ•°**ï¼Œæˆ‘ä»¬å°±æœ‰ä¸€ä¸ªæœ€ä¼˜çš„ç­–ç•¥ï¼Œå› ä¸ºæˆ‘ä»¬**çŸ¥é“å¯¹äºæ¯ä¸ªçŠ¶æ€ï¼Œæœ€ä½³çš„åŠ¨ä½œæ˜¯ä»€ä¹ˆ**ã€‚

<img src="https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit3/link-value-policy.jpg" alt="Link value policy"  width="100%"/>


ä½†æ˜¯ï¼Œåœ¨å¼€å§‹æ—¶ï¼Œæˆ‘ä»¬çš„**Qè¡¨æ˜¯æ²¡ç”¨çš„ï¼Œå› ä¸ºå®ƒä¸ºæ¯ä¸ªçŠ¶æ€-åŠ¨ä½œå¯¹æä¾›äº†ä»»æ„å€¼ï¼ˆå¤§å¤šæ•°æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å°†Qè¡¨åˆå§‹åŒ–ä¸º0å€¼ï¼‰**ã€‚ä½†æ˜¯ï¼Œéšç€æˆ‘ä»¬æ¢ç´¢ç¯å¢ƒå¹¶æ›´æ–°æˆ‘ä»¬çš„Qè¡¨ï¼Œå®ƒå°†ç»™æˆ‘ä»¬è¶Šæ¥è¶Šå¥½çš„è¿‘ä¼¼å€¼ã€‚

<img src="https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/notebooks/unit2/q-learning.jpeg" alt="q-learning.jpeg" width="100%"/>

è¿™æ˜¯Q-Learningçš„ä¼ªä»£ç ï¼š

<img src="https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit3/Q-learning-2.jpg" alt="Q-Learning" width="100%"/>


# è®©æˆ‘ä»¬ç¼–å†™æˆ‘ä»¬çš„ç¬¬ä¸€ä¸ªå¼ºåŒ–å­¦ä¹ ç®—æ³• ğŸš€

ä¸ºäº†åœ¨[è®¤è¯æµç¨‹](https://huggingface.co/deep-rl-course/en/unit0/introduction#certification-process)ä¸­éªŒè¯è¿™ä¸ªå®è·µç»ƒä¹ ï¼Œä½ éœ€è¦å°†è®­ç»ƒå¥½çš„å‡ºç§Ÿè½¦æ¨¡å‹æ¨é€åˆ°Hubï¼Œå¹¶**è·å¾— >= 4.5çš„ç»“æœ**ã€‚

è¦æŸ¥æ‰¾ä½ çš„ç»“æœï¼Œè¯·å‰å¾€[æ’è¡Œæ¦œ](https://huggingface.co/spaces/huggingface-projects/Deep-Reinforcement-Learning-Leaderboard)å¹¶æ‰¾åˆ°ä½ çš„æ¨¡å‹ï¼Œ**ç»“æœ = å¹³å‡å¥–åŠ± - å¥–åŠ±çš„æ ‡å‡†å·®**

æœ‰å…³è®¤è¯æµç¨‹çš„æ›´å¤šä¿¡æ¯ï¼Œè¯·æŸ¥çœ‹æ­¤éƒ¨åˆ† ğŸ‘‰ https://huggingface.co/deep-rl-course/en/unit0/introduction#certification-process

## å®‰è£…ä¾èµ–é¡¹å¹¶åˆ›å»ºè™šæ‹Ÿæ˜¾ç¤ºå™¨ ğŸ”½

åœ¨ç¬”è®°æœ¬ä¸­ï¼Œæˆ‘ä»¬éœ€è¦ç”Ÿæˆå›æ”¾è§†é¢‘ã€‚ä¸ºæ­¤ï¼Œåœ¨Colabä¸­ï¼Œ**æˆ‘ä»¬éœ€è¦æœ‰ä¸€ä¸ªè™šæ‹Ÿå±å¹•æ¥æ¸²æŸ“ç¯å¢ƒ**ï¼ˆå¹¶å› æ­¤è®°å½•å¸§ï¼‰ã€‚

å› æ­¤ï¼Œä»¥ä¸‹å•å…ƒå°†å®‰è£…åº“å¹¶åˆ›å»ºå¹¶è¿è¡Œè™šæ‹Ÿå±å¹• ğŸ–¥

æˆ‘ä»¬å°†å®‰è£…å¤šä¸ªåº“ï¼š

- `gymnasium`ï¼šåŒ…å«FrozenLake-v1 â›„ å’ŒTaxi-v3 ğŸš• ç¯å¢ƒã€‚
- `pygame`ï¼šç”¨äºFrozenLake-v1å’ŒTaxi-v3çš„UIã€‚
- `numpy`ï¼šç”¨äºå¤„ç†æˆ‘ä»¬çš„Qè¡¨ã€‚

Hugging Face Hub ğŸ¤— ä½œä¸ºä¸€ä¸ªä¸­å¿ƒä½ç½®ï¼Œä»»ä½•äººéƒ½å¯ä»¥åœ¨è¿™é‡Œåˆ†äº«å’Œæ¢ç´¢æ¨¡å‹å’Œæ•°æ®é›†ã€‚å®ƒå…·æœ‰ç‰ˆæœ¬æ§åˆ¶ã€æŒ‡æ ‡ã€å¯è§†åŒ–å’Œå…¶ä»–åŠŸèƒ½ï¼Œè¿™äº›åŠŸèƒ½å°†ä½¿ä½ èƒ½å¤Ÿè½»æ¾åœ°ä¸ä»–äººåä½œã€‚

ä½ å¯ä»¥åœ¨è¿™é‡ŒæŸ¥çœ‹æ‰€æœ‰å¯ç”¨çš„æ·±åº¦å¼ºåŒ–å­¦ä¹ æ¨¡å‹ï¼ˆå¦‚æœå®ƒä»¬ä½¿ç”¨Q Learningï¼‰ğŸ‘‰ https://huggingface.co/models?other=q-learning

```bash
pip install -r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit2/requirements-unit2.txt
```

```bash
sudo apt-get update
sudo apt-get install -y python3-opengl
apt install ffmpeg xvfb
pip3 install pyvirtualdisplay
```

ä¸ºäº†ç¡®ä¿ä½¿ç”¨æ–°å®‰è£…çš„åº“ï¼Œ**æœ‰æ—¶éœ€è¦é‡å¯ç¬”è®°æœ¬è¿è¡Œæ—¶**ã€‚ä¸‹ä¸€ä¸ªå•å…ƒå°†å¼ºåˆ¶**è¿è¡Œæ—¶å´©æºƒï¼Œæ‰€ä»¥ä½ éœ€è¦é‡æ–°è¿æ¥å¹¶ä»è¿™é‡Œå¼€å§‹è¿è¡Œä»£ç **ã€‚å¤šäºäº†è¿™ä¸ªæŠ€å·§ï¼Œ**æˆ‘ä»¬å°†èƒ½å¤Ÿè¿è¡Œæˆ‘ä»¬çš„è™šæ‹Ÿå±å¹•**ã€‚

```python
import os

os.kill(os.getpid(), 9)
```

```python
# è™šæ‹Ÿæ˜¾ç¤ºå™¨
from pyvirtualdisplay import Display

virtual_display = Display(visible=0, size=(1400, 900))
virtual_display.start()
```

## å¯¼å…¥åŒ… ğŸ“¦

é™¤äº†å®‰è£…çš„åº“å¤–ï¼Œæˆ‘ä»¬è¿˜ä½¿ç”¨ï¼š

- `random`ï¼šç”Ÿæˆéšæœºæ•°ï¼ˆå¯¹äºepsilon-greedyç­–ç•¥å¾ˆæœ‰ç”¨ï¼‰ã€‚
- `imageio`ï¼šç”Ÿæˆå›æ”¾è§†é¢‘ã€‚

```python
import numpy as np
import gymnasium as gym
import random
import imageio
import os
import tqdm

import pickle5 as pickle
from tqdm.notebook import tqdm
```

æˆ‘ä»¬ç°åœ¨å‡†å¤‡å¥½ç¼–å†™æˆ‘ä»¬çš„Q-Learningç®—æ³•äº† ğŸ”¥

# ç¬¬1éƒ¨åˆ†ï¼šå†°æ¹– â›„ï¼ˆéæ»‘åŠ¨ç‰ˆæœ¬ï¼‰

## åˆ›å»ºå¹¶ç†è§£[FrozenLakeç¯å¢ƒ â›„]((https://gymnasium.farama.org/environments/toy_text/frozen_lake/)
---

ğŸ’¡ å½“ä½ å¼€å§‹ä½¿ç”¨ä¸€ä¸ªç¯å¢ƒæ—¶ï¼Œä¸€ä¸ªå¥½ä¹ æƒ¯æ˜¯æŸ¥çœ‹å®ƒçš„æ–‡æ¡£

ğŸ‘‰ https://gymnasium.farama.org/environments/toy_text/frozen_lake/

---

æˆ‘ä»¬å°†è®­ç»ƒæˆ‘ä»¬çš„Q-Learningæ™ºèƒ½ä½“**ä»èµ·å§‹çŠ¶æ€(S)å¯¼èˆªåˆ°ç›®æ ‡çŠ¶æ€(G)ï¼Œåªåœ¨å†°å†»çš„ç“¦ç‰‡(F)ä¸Šè¡Œèµ°ï¼Œå¹¶é¿å¼€æ´(H)**ã€‚

æˆ‘ä»¬å¯ä»¥æœ‰ä¸¤ç§å¤§å°çš„ç¯å¢ƒï¼š

- `map_name="4x4"`ï¼š4x4ç½‘æ ¼ç‰ˆæœ¬
- `map_name="8x8"`ï¼š8x8ç½‘æ ¼ç‰ˆæœ¬


ç¯å¢ƒæœ‰ä¸¤ç§æ¨¡å¼ï¼š

- `is_slippery=False`ï¼šç”±äºå†°æ¹–çš„éæ»‘åŠ¨æ€§è´¨ï¼Œæ™ºèƒ½ä½“æ€»æ˜¯**æœç€é¢„æœŸæ–¹å‘ç§»åŠ¨**ï¼ˆç¡®å®šæ€§ï¼‰ã€‚
- `is_slippery=True`ï¼šç”±äºå†°æ¹–çš„æ»‘åŠ¨æ€§è´¨ï¼Œæ™ºèƒ½ä½“**å¯èƒ½ä¸æ€»æ˜¯æœç€é¢„æœŸæ–¹å‘ç§»åŠ¨**ï¼ˆéšæœºæ€§ï¼‰ã€‚

ç°åœ¨è®©æˆ‘ä»¬ä¿æŒç®€å•ï¼Œä½¿ç”¨4x4åœ°å›¾å’Œéæ»‘åŠ¨ç‰ˆæœ¬ã€‚
æˆ‘ä»¬æ·»åŠ ä¸€ä¸ªåä¸º`render_mode`çš„å‚æ•°ï¼ŒæŒ‡å®šç¯å¢ƒåº”å¦‚ä½•å¯è§†åŒ–ã€‚åœ¨æˆ‘ä»¬çš„ä¾‹å­ä¸­ï¼Œå› ä¸ºæˆ‘ä»¬**æƒ³åœ¨æœ€åè®°å½•ç¯å¢ƒçš„è§†é¢‘ï¼Œæˆ‘ä»¬éœ€è¦å°†render_modeè®¾ç½®ä¸ºrgb_array**ã€‚

æ­£å¦‚[æ–‡æ¡£ä¸­è§£é‡Šçš„](https://gymnasium.farama.org/api/env/#gymnasium.Env.render) "rgb_array"ï¼šè¿”å›è¡¨ç¤ºç¯å¢ƒå½“å‰çŠ¶æ€çš„å•ä¸ªå¸§ã€‚å¸§æ˜¯ä¸€ä¸ªå½¢çŠ¶ä¸º(x, y, 3)çš„np.ndarrayï¼Œè¡¨ç¤ºxä¹˜yåƒç´ å›¾åƒçš„RGBå€¼ã€‚

```python
# ä½¿ç”¨4x4åœ°å›¾å’Œéæ»‘åŠ¨ç‰ˆæœ¬åˆ›å»ºFrozenLake-v1ç¯å¢ƒï¼Œå¹¶è®¾ç½®render_mode="rgb_array"
env = gym.make()  # TODO ä½¿ç”¨æ­£ç¡®çš„å‚æ•°
```

### è§£å†³æ–¹æ¡ˆ

```python
env = gym.make("FrozenLake-v1", map_name="4x4", is_slippery=False, render_mode="rgb_array")
```

ä½ å¯ä»¥åƒè¿™æ ·åˆ›å»ºè‡ªå·±çš„è‡ªå®šä¹‰ç½‘æ ¼ï¼š

```python
desc=["SFFF", "FHFH", "FFFH", "HFFG"]
gym.make('FrozenLake-v1', desc=desc, is_slippery=True)
```

ä½†æˆ‘ä»¬ç°åœ¨å°†ä½¿ç”¨é»˜è®¤ç¯å¢ƒã€‚

### è®©æˆ‘ä»¬çœ‹çœ‹ç¯å¢ƒæ˜¯ä»€ä¹ˆæ ·å­çš„ï¼š


```python
# æˆ‘ä»¬ä½¿ç”¨gym.make("<ç¯å¢ƒåç§°>")åˆ›å»ºç¯å¢ƒ- `is_slippery=False`ï¼šç”±äºå†°æ¹–çš„éæ»‘åŠ¨æ€§è´¨ï¼Œæ™ºèƒ½ä½“æ€»æ˜¯æœç€é¢„æœŸæ–¹å‘ç§»åŠ¨ï¼ˆç¡®å®šæ€§ï¼‰ã€‚
print("_____è§‚å¯Ÿç©ºé—´_____ \n")
print("è§‚å¯Ÿç©ºé—´", env.observation_space)
print("æ ·æœ¬è§‚å¯Ÿ", env.observation_space.sample())  # è·å–éšæœºè§‚å¯Ÿ
```

æˆ‘ä»¬é€šè¿‡`è§‚å¯Ÿç©ºé—´å½¢çŠ¶ Discrete(16)`çœ‹åˆ°ï¼Œè§‚å¯Ÿæ˜¯ä¸€ä¸ªæ•´æ•°ï¼Œè¡¨ç¤º**æ™ºèƒ½ä½“å½“å‰ä½ç½®ä¸ºcurrent_row * ncols + current_colï¼ˆå…¶ä¸­è¡Œå’Œåˆ—éƒ½ä»0å¼€å§‹ï¼‰**ã€‚

ä¾‹å¦‚ï¼Œ4x4åœ°å›¾ä¸­çš„ç›®æ ‡ä½ç½®å¯ä»¥è®¡ç®—å¦‚ä¸‹ï¼š3 * 4 + 3 = 15ã€‚å¯èƒ½çš„è§‚å¯Ÿæ•°é‡å–å†³äºåœ°å›¾çš„å¤§å°ã€‚**ä¾‹å¦‚ï¼Œ4x4åœ°å›¾æœ‰16ä¸ªå¯èƒ½çš„è§‚å¯Ÿ**ã€‚


ä¾‹å¦‚ï¼Œè¿™æ˜¯çŠ¶æ€ = 0çš„æ ·å­ï¼š

<img src="https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/notebooks/unit2/frozenlake.png" alt="FrozenLake" />

```python
print("\n _____åŠ¨ä½œç©ºé—´_____ \n")
print("åŠ¨ä½œç©ºé—´å½¢çŠ¶", env.action_space.n)
print("åŠ¨ä½œç©ºé—´æ ·æœ¬", env.action_space.sample())  # é‡‡å–éšæœºåŠ¨ä½œ
```

åŠ¨ä½œç©ºé—´ï¼ˆæ™ºèƒ½ä½“å¯ä»¥é‡‡å–çš„å¯èƒ½åŠ¨ä½œé›†ï¼‰æ˜¯ç¦»æ•£çš„ï¼Œæœ‰4ä¸ªå¯ç”¨åŠ¨ä½œ ğŸ®ï¼š
- 0: å‘å·¦èµ°
- 1: å‘ä¸‹èµ°
- 2: å‘å³èµ°
- 3: å‘ä¸Šèµ°

å¥–åŠ±å‡½æ•° ğŸ’°ï¼š
- åˆ°è¾¾ç›®æ ‡ï¼š+1
- åˆ°è¾¾æ´ï¼š0
- åˆ°è¾¾å†°é¢ï¼š0

## åˆ›å»ºå¹¶åˆå§‹åŒ–Qè¡¨ ğŸ—„ï¸

(ğŸ‘€ ä¼ªä»£ç çš„ç¬¬1æ­¥)

<img src="https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit3/Q-learning-2.jpg" alt="Q-Learning" width="100%"/>


æ˜¯æ—¶å€™åˆå§‹åŒ–æˆ‘ä»¬çš„Qè¡¨äº†ï¼è¦çŸ¥é“ä½¿ç”¨å¤šå°‘è¡Œï¼ˆçŠ¶æ€ï¼‰å’Œåˆ—ï¼ˆåŠ¨ä½œï¼‰ï¼Œæˆ‘ä»¬éœ€è¦çŸ¥é“åŠ¨ä½œå’Œè§‚å¯Ÿç©ºé—´ã€‚æˆ‘ä»¬å·²ç»ä»å‰é¢çŸ¥é“äº†å®ƒä»¬çš„å€¼ï¼Œä½†æˆ‘ä»¬å¸Œæœ›ä»¥ç¼–ç¨‹æ–¹å¼è·å–å®ƒä»¬ï¼Œä»¥ä¾¿æˆ‘ä»¬çš„ç®—æ³•èƒ½å¤Ÿé€‚ç”¨äºä¸åŒçš„ç¯å¢ƒã€‚Gymä¸ºæˆ‘ä»¬æä¾›äº†ä¸€ç§æ–¹æ³•ï¼š`env.action_space.n`å’Œ`env.observation_space.n`


```python
state_space =
print("æœ‰ ", state_space, " ä¸ªå¯èƒ½çš„çŠ¶æ€")

action_space =
print("æœ‰ ", action_space, " ä¸ªå¯èƒ½çš„åŠ¨ä½œ")
```

```python
# è®©æˆ‘ä»¬åˆ›å»ºå¤§å°ä¸º(state_space, action_space)çš„Qè¡¨ï¼Œå¹¶ä½¿ç”¨np.zeroså°†æ¯ä¸ªå€¼åˆå§‹åŒ–ä¸º0ã€‚np.zeroséœ€è¦ä¸€ä¸ªå…ƒç»„(a,b)
def initialize_q_table(state_space, action_space):
  Qtable =
  return Qtable
```

```python
Qtable_frozenlake = initialize_q_table(state_space, action_space)
```

### è§£å†³æ–¹æ¡ˆ

```python
state_space = env.observation_space.n
print("æœ‰ ", state_space, " ä¸ªå¯èƒ½çš„çŠ¶æ€")

action_space = env.action_space.n
print("æœ‰ ", action_space, " ä¸ªå¯èƒ½çš„åŠ¨ä½œ")
```

```python
# è®©æˆ‘ä»¬åˆ›å»ºå¤§å°ä¸º(state_space, action_space)çš„Qè¡¨ï¼Œå¹¶ä½¿ç”¨np.zeroså°†æ¯ä¸ªå€¼åˆå§‹åŒ–ä¸º0
def initialize_q_table(state_space, action_space):
    Qtable = np.zeros((state_space, action_space))
    return Qtable
```

```python
Qtable_frozenlake = initialize_q_table(state_space, action_space)
```

## å®šä¹‰è´ªå©ªç­–ç•¥ ğŸ¤–

è®°ä½æˆ‘ä»¬æœ‰ä¸¤ç§ç­–ç•¥ï¼Œå› ä¸ºQ-Learningæ˜¯ä¸€ç§**ç¦»ç­–ç•¥ï¼ˆoff-policyï¼‰**ç®—æ³•ã€‚è¿™æ„å‘³ç€æˆ‘ä»¬**ä½¿ç”¨ä¸åŒçš„ç­–ç•¥æ¥è¡ŒåŠ¨å’Œæ›´æ–°ä»·å€¼å‡½æ•°**ã€‚

- Epsilon-è´ªå©ªç­–ç•¥ï¼ˆè¡ŒåŠ¨ç­–ç•¥ï¼‰
- è´ªå©ªç­–ç•¥ï¼ˆæ›´æ–°ç­–ç•¥ï¼‰

è´ªå©ªç­–ç•¥ä¹Ÿå°†æ˜¯Q-learningæ™ºèƒ½ä½“å®Œæˆè®­ç»ƒåæˆ‘ä»¬å°†æ‹¥æœ‰çš„æœ€ç»ˆç­–ç•¥ã€‚è´ªå©ªç­–ç•¥ç”¨äºä½¿ç”¨Qè¡¨é€‰æ‹©åŠ¨ä½œã€‚

<img src="https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit3/off-on-4.jpg" alt="Q-Learning" width="100%"/>


```python
def greedy_policy(Qtable, state):
  # åˆ©ç”¨ï¼šé€‰æ‹©å…·æœ‰æœ€é«˜çŠ¶æ€-åŠ¨ä½œå€¼çš„åŠ¨ä½œ
  action = 

  return action
```

#### è§£å†³æ–¹æ¡ˆ

```python
def greedy_policy(Qtable, state):
    # åˆ©ç”¨ï¼šé€‰æ‹©å…·æœ‰æœ€é«˜çŠ¶æ€-åŠ¨ä½œå€¼çš„åŠ¨ä½œ
    action = np.argmax(Qtable[state][:])

    return action
```

## å®šä¹‰epsilon-è´ªå©ªç­–ç•¥ ğŸ¤–

Epsilon-è´ªå©ªæ˜¯å¤„ç†æ¢ç´¢/åˆ©ç”¨æƒè¡¡çš„è®­ç»ƒç­–ç•¥ã€‚

Epsilon-è´ªå©ªçš„æ€æƒ³æ˜¯ï¼š

- ä»¥*æ¦‚ç‡1 - É›*ï¼š**æˆ‘ä»¬è¿›è¡Œåˆ©ç”¨**ï¼ˆå³æˆ‘ä»¬çš„æ™ºèƒ½ä½“é€‰æ‹©å…·æœ‰æœ€é«˜çŠ¶æ€-åŠ¨ä½œå¯¹å€¼çš„åŠ¨ä½œï¼‰ã€‚

- ä»¥*æ¦‚ç‡É›*ï¼šæˆ‘ä»¬è¿›è¡Œ**æ¢ç´¢**ï¼ˆå°è¯•éšæœºåŠ¨ä½œï¼‰ã€‚

éšç€è®­ç»ƒçš„ç»§ç»­ï¼Œæˆ‘ä»¬é€æ¸**å‡å°‘epsilonå€¼ï¼Œå› ä¸ºæˆ‘ä»¬éœ€è¦è¶Šæ¥è¶Šå°‘çš„æ¢ç´¢å’Œæ›´å¤šçš„åˆ©ç”¨ã€‚**

<img src="https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit3/Q-learning-4.jpg" alt="Q-Learning" width="100%"/>


```python
def epsilon_greedy_policy(Qtable, state, epsilon):
  # éšæœºç”Ÿæˆä¸€ä¸ª0åˆ°1ä¹‹é—´çš„æ•°
  random_num = 
  # å¦‚æœrandom_num > epsilon --> åˆ©ç”¨
  if random_num > epsilon:
    # é€‰æ‹©ç»™å®šçŠ¶æ€ä¸‹å€¼æœ€é«˜çš„åŠ¨ä½œ
    # np.argmaxåœ¨è¿™é‡Œå¾ˆæœ‰ç”¨
    action = 
  # å¦åˆ™ --> æ¢ç´¢
  else:
    action = # éšæœºé€‰æ‹©ä¸€ä¸ªåŠ¨ä½œ

  return action
```

#### è§£å†³æ–¹æ¡ˆ

```python
def epsilon_greedy_policy(Qtable, state, epsilon):
    # éšæœºç”Ÿæˆä¸€ä¸ª0åˆ°1ä¹‹é—´çš„æ•°
    random_num = random.uniform(0, 1)
    # å¦‚æœrandom_num > epsilon --> åˆ©ç”¨
    if random_num > epsilon:
        # é€‰æ‹©ç»™å®šçŠ¶æ€ä¸‹å€¼æœ€é«˜çš„åŠ¨ä½œ
        # np.argmaxåœ¨è¿™é‡Œå¾ˆæœ‰ç”¨
        action = greedy_policy(Qtable, state)
    # å¦åˆ™ --> æ¢ç´¢
    else:
        action = env.action_space.sample()

    return action
```

## å®šä¹‰è¶…å‚æ•° âš™ï¸

ä¸æ¢ç´¢ç›¸å…³çš„è¶…å‚æ•°æ˜¯æœ€é‡è¦çš„å‚æ•°ä¹‹ä¸€ã€‚

- æˆ‘ä»¬éœ€è¦ç¡®ä¿æˆ‘ä»¬çš„æ™ºèƒ½ä½“**æ¢ç´¢è¶³å¤Ÿå¤šçš„çŠ¶æ€ç©ºé—´**ä»¥å­¦ä¹ è‰¯å¥½çš„ä»·å€¼è¿‘ä¼¼ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬éœ€è¦é€æ¸é™ä½epsilonã€‚
- å¦‚æœä½ é™ä½epsilonå¤ªå¿«ï¼ˆè¡°å‡ç‡å¤ªé«˜ï¼‰ï¼Œ**ä½ çš„æ™ºèƒ½ä½“å¯èƒ½ä¼šé™·å…¥å›°å¢ƒ**ï¼Œå› ä¸ºä½ çš„æ™ºèƒ½ä½“æ²¡æœ‰æ¢ç´¢è¶³å¤Ÿå¤šçš„çŠ¶æ€ç©ºé—´ï¼Œå› æ­¤æ— æ³•è§£å†³é—®é¢˜ã€‚

```python
# è®­ç»ƒå‚æ•°
n_training_episodes = 10000  # æ€»è®­ç»ƒå›åˆæ•°
learning_rate = 0.7  # å­¦ä¹ ç‡

# è¯„ä¼°å‚æ•°
n_eval_episodes = 100  # æµ‹è¯•å›åˆæ€»æ•°

# ç¯å¢ƒå‚æ•°
env_id = "FrozenLake-v1"  # ç¯å¢ƒåç§°
max_steps = 99  # æ¯å›åˆæœ€å¤§æ­¥æ•°
gamma = 0.95  # æŠ˜æ‰£ç‡
eval_seed = []  # ç¯å¢ƒçš„è¯„ä¼°ç§å­

# æ¢ç´¢å‚æ•°
max_epsilon = 1.0  # å¼€å§‹æ—¶çš„æ¢ç´¢æ¦‚ç‡
min_epsilon = 0.05  # æœ€å°æ¢ç´¢æ¦‚ç‡
decay_rate = 0.0005  # æ¢ç´¢æ¦‚ç‡çš„æŒ‡æ•°è¡°å‡ç‡
```

## åˆ›å»ºè®­ç»ƒå¾ªç¯æ–¹æ³•

<img src="https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit3/Q-learning-2.jpg" alt="Q-Learning" width="100%"/>

è®­ç»ƒå¾ªç¯å¦‚ä¸‹ï¼š

```
å¯¹äºæ€»è®­ç»ƒå›åˆä¸­çš„æ¯ä¸ªå›åˆï¼š

å‡å°‘epsilonï¼ˆå› ä¸ºæˆ‘ä»¬éœ€è¦è¶Šæ¥è¶Šå°‘çš„æ¢ç´¢ï¼‰
é‡ç½®ç¯å¢ƒ

  å¯¹äºæœ€å¤§æ—¶é—´æ­¥æ•°ä¸­çš„æ¯ä¸€æ­¥ï¼š
    ä½¿ç”¨epsilonè´ªå©ªç­–ç•¥é€‰æ‹©åŠ¨ä½œAt
    æ‰§è¡ŒåŠ¨ä½œ(a)å¹¶è§‚å¯Ÿç»“æœçŠ¶æ€(s')å’Œå¥–åŠ±(r)
    ä½¿ç”¨è´å°”æ›¼æ–¹ç¨‹æ›´æ–°Qå€¼ Q(s,a) + lr [R(s,a) + gamma * max Q(s',a') - Q(s,a)]
    å¦‚æœå®Œæˆï¼Œç»“æŸå›åˆ
    æˆ‘ä»¬çš„ä¸‹ä¸€ä¸ªçŠ¶æ€æ˜¯æ–°çŠ¶æ€
```

```python
def train(n_training_episodes, min_epsilon, max_epsilon, decay_rate, env, max_steps, Qtable):
  for episode in tqdm(range(n_training_episodes)):
    # å‡å°‘epsilonï¼ˆå› ä¸ºæˆ‘ä»¬éœ€è¦è¶Šæ¥è¶Šå°‘çš„æ¢ç´¢ï¼‰
    epsilon = min_epsilon + (max_epsilon - min_epsilon)*np.exp(-decay_rate*episode)
    # é‡ç½®ç¯å¢ƒ
    state, info = env.reset()
    step = 0
    terminated = False
    truncated = False

    # é‡å¤
    for step in range(max_steps):
      # ä½¿ç”¨epsilonè´ªå©ªç­–ç•¥é€‰æ‹©åŠ¨ä½œAt
      action = 

      # æ‰§è¡ŒåŠ¨ä½œAtå¹¶è§‚å¯ŸRt+1å’ŒSt+1
      # æ‰§è¡ŒåŠ¨ä½œ(a)å¹¶è§‚å¯Ÿç»“æœçŠ¶æ€(s')å’Œå¥–åŠ±(r)
      new_state, reward, terminated, truncated, info = 

      # æ›´æ–°Q(s,a):= Q(s,a) + lr [R(s,a) + gamma * max Q(s',a') - Q(s,a)]
      Qtable[state][action] = 

      # å¦‚æœç»ˆæ­¢æˆ–æˆªæ–­ï¼Œç»“æŸå›åˆ
      if terminated or truncated:
        break

      # æˆ‘ä»¬çš„ä¸‹ä¸€ä¸ªçŠ¶æ€æ˜¯æ–°çŠ¶æ€
      state = new_state
  return Qtable
```

#### è§£å†³æ–¹æ¡ˆ

```python
def train(n_training_episodes, min_epsilon, max_epsilon, decay_rate, env, max_steps, Qtable):
    for episode in tqdm(range(n_training_episodes)):
        # å‡å°‘epsilonï¼ˆå› ä¸ºæˆ‘ä»¬éœ€è¦è¶Šæ¥è¶Šå°‘çš„æ¢ç´¢ï¼‰
        epsilon = min_epsilon + (max_epsilon - min_epsilon) * np.exp(-decay_rate * episode)
        # é‡ç½®ç¯å¢ƒ
        state, info = env.reset()
        step = 0
        terminated = False
        truncated = False

        # é‡å¤
        for step in range(max_steps):
            # ä½¿ç”¨epsilonè´ªå©ªç­–ç•¥é€‰æ‹©åŠ¨ä½œAt
            action = epsilon_greedy_policy(Qtable, state, epsilon)

            # æ‰§è¡ŒåŠ¨ä½œAtå¹¶è§‚å¯ŸRt+1å’ŒSt+1
            # æ‰§è¡ŒåŠ¨ä½œ(a)å¹¶è§‚å¯Ÿç»“æœçŠ¶æ€(s')å’Œå¥–åŠ±(r)
            new_state, reward, terminated, truncated, info = env.step(action)

            # æ›´æ–°Q(s,a):= Q(s,a) + lr [R(s,a) + gamma * max Q(s',a') - Q(s,a)]
            Qtable[state][action] = Qtable[state][action] + learning_rate * (
                reward + gamma * np.max(Qtable[new_state]) - Qtable[state][action]
            )

            # å¦‚æœç»ˆæ­¢æˆ–æˆªæ–­ï¼Œç»“æŸå›åˆ
            if terminated or truncated:
                break

            # æˆ‘ä»¬çš„ä¸‹ä¸€ä¸ªçŠ¶æ€æ˜¯æ–°çŠ¶æ€
            state = new_state
    return Qtable
```

## è®­ç»ƒQ-Learningæ™ºèƒ½ä½“ ğŸƒ

```python
Qtable_frozenlake = train(n_training_episodes, min_epsilon, max_epsilon, decay_rate, env, max_steps, Qtable_frozenlake)
```

## è®©æˆ‘ä»¬çœ‹çœ‹æˆ‘ä»¬çš„Q-Learningè¡¨ç°åœ¨æ˜¯ä»€ä¹ˆæ ·å­ ğŸ‘€

```python
Qtable_frozenlake
```

## è¯„ä¼°æ–¹æ³• ğŸ“

- æˆ‘ä»¬å®šä¹‰äº†å°†ç”¨äºæµ‹è¯•æˆ‘ä»¬çš„Q-Learningæ™ºèƒ½ä½“çš„è¯„ä¼°æ–¹æ³•ã€‚

```python
def evaluate_agent(env, max_steps, n_eval_episodes, Q, seed):
    """
    è¯„ä¼°æ™ºèƒ½ä½“``n_eval_episodes``å›åˆå¹¶è¿”å›å¹³å‡å¥–åŠ±å’Œå¥–åŠ±çš„æ ‡å‡†å·®ã€‚
    :param env: è¯„ä¼°ç¯å¢ƒ
    :param n_eval_episodes: è¯„ä¼°æ™ºèƒ½ä½“çš„å›åˆæ•°
    :param Q: Qè¡¨
    :param seed: è¯„ä¼°ç§å­æ•°ç»„ï¼ˆç”¨äºtaxi-v3ï¼‰
    """
    episode_rewards = []
    for episode in tqdm(range(n_eval_episodes)):
        if seed:
            state, info = env.reset(seed=seed[episode])
        else:
            state, info = env.reset()
        step = 0
        truncated = False
        terminated = False
        total_rewards_ep = 0

        for step in range(max_steps):
            # é€‰æ‹©åœ¨ç»™å®šçŠ¶æ€ä¸‹å…·æœ‰æœ€å¤§é¢„æœŸæœªæ¥å¥–åŠ±çš„åŠ¨ä½œï¼ˆç´¢å¼•ï¼‰
            action = greedy_policy(Q, state)
            new_state, reward, terminated, truncated, info = env.step(action)
            total_rewards_ep += reward

            if terminated or truncated:
                break
            state = new_state
        episode_rewards.append(total_rewards_ep)
    mean_reward = np.mean(episode_rewards)
    std_reward = np.std(episode_rewards)

    return mean_reward, std_reward
```

## è¯„ä¼°æˆ‘ä»¬çš„Q-Learningæ™ºèƒ½ä½“ ğŸ“ˆ

- é€šå¸¸ï¼Œä½ åº”è¯¥æœ‰1.0çš„å¹³å‡å¥–åŠ±
- **ç¯å¢ƒç›¸å¯¹ç®€å•**ï¼Œå› ä¸ºçŠ¶æ€ç©ºé—´éå¸¸å°ï¼ˆ16ï¼‰ã€‚ä½ å¯ä»¥å°è¯•çš„æ˜¯[ç”¨æ»‘åŠ¨ç‰ˆæœ¬æ›¿æ¢å®ƒ](https://www.gymlibrary.dev/environments/toy_text/frozen_lake/)ï¼Œè¿™å¼•å…¥äº†éšæœºæ€§ï¼Œä½¿ç¯å¢ƒæ›´åŠ å¤æ‚ã€‚

```python
# è¯„ä¼°æˆ‘ä»¬çš„æ™ºèƒ½ä½“
mean_reward, std_reward = evaluate_agent(env, max_steps, n_eval_episodes, Qtable_frozenlake, eval_seed)
print(f"å¹³å‡å¥–åŠ±={mean_reward:.2f} +/- {std_reward:.2f}")
```

## å°†æˆ‘ä»¬è®­ç»ƒå¥½çš„æ¨¡å‹å‘å¸ƒåˆ°Hub ğŸ”¥

ç°åœ¨æˆ‘ä»¬åœ¨è®­ç»ƒåçœ‹åˆ°äº†è‰¯å¥½çš„ç»“æœï¼Œ**æˆ‘ä»¬å¯ä»¥ç”¨ä¸€è¡Œä»£ç å°†æˆ‘ä»¬è®­ç»ƒå¥½çš„æ¨¡å‹å‘å¸ƒåˆ°Hub ğŸ¤—**ã€‚

è¿™æ˜¯ä¸€ä¸ªæ¨¡å‹å¡ç‰‡çš„ä¾‹å­ï¼š

<img src="https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/notebooks/unit2/modelcard.png" alt="Model card" width="100%"/>


åœ¨åº•å±‚ï¼ŒHubä½¿ç”¨åŸºäºgitçš„ä»“åº“ï¼ˆå¦‚æœä½ ä¸çŸ¥é“gitæ˜¯ä»€ä¹ˆï¼Œä¸ç”¨æ‹…å¿ƒï¼‰ï¼Œè¿™æ„å‘³ç€ä½ å¯ä»¥åœ¨å®éªŒå’Œæ”¹è¿›ä½ çš„æ™ºèƒ½ä½“æ—¶ç”¨æ–°ç‰ˆæœ¬æ›´æ–°æ¨¡å‹ã€‚

#### è¯·å‹¿ä¿®æ”¹æ­¤ä»£ç 

```python
from huggingface_hub import HfApi, snapshot_download
from huggingface_hub.repocard import metadata_eval_result, metadata_save

from pathlib import Path
import datetime
import json
```

```python
def record_video(env, Qtable, out_directory, fps=1):
    """
    ç”Ÿæˆæ™ºèƒ½ä½“çš„å›æ”¾è§†é¢‘
    :param env
    :param Qtable: æˆ‘ä»¬æ™ºèƒ½ä½“çš„Qè¡¨
    :param out_directory
    :param fps: æ¯ç§’å¤šå°‘å¸§ï¼ˆå¯¹äºtaxi-v3å’Œfrozenlake-v1æˆ‘ä»¬ä½¿ç”¨1ï¼‰
    """
    images = []
    terminated = False
    truncated = False
    state, info = env.reset(seed=random.randint(0, 500))
    img = env.render()
    images.append(img)
    while not terminated or truncated:
        # é€‰æ‹©åœ¨ç»™å®šçŠ¶æ€ä¸‹å…·æœ‰æœ€å¤§é¢„æœŸæœªæ¥å¥–åŠ±çš„åŠ¨ä½œï¼ˆç´¢å¼•ï¼‰
        action = np.argmax(Qtable[state][:])
        state, reward, terminated, truncated, info = env.step(
            action
        )  # ä¸ºäº†è®°å½•é€»è¾‘ï¼Œæˆ‘ä»¬ç›´æ¥å°†next_state = state
        img = env.render()
        images.append(img)
    imageio.mimsave(out_directory, [np.array(img) for i, img in enumerate(images)], fps=fps)
```

```python
def push_to_hub(repo_id, model, env, video_fps=1, local_repo_path="hub"):
    """
    è¯„ä¼°ã€ç”Ÿæˆè§†é¢‘å¹¶å°†æ¨¡å‹ä¸Šä¼ åˆ°Hugging Face Hubã€‚
    æ­¤æ–¹æ³•å®Œæˆæ•´ä¸ªæµç¨‹ï¼š
    - è¯„ä¼°æ¨¡å‹
    - ç”Ÿæˆæ¨¡å‹å¡ç‰‡
    - ç”Ÿæˆæ™ºèƒ½ä½“çš„å›æ”¾è§†é¢‘
    - å°†æ‰€æœ‰å†…å®¹æ¨é€åˆ°Hub

    :param repo_id: repo_id: Hugging Face Hubä¸Šæ¨¡å‹ä»“åº“çš„ID
    :param env
    :param video_fps: è®°å½•è§†é¢‘å›æ”¾çš„æ¯ç§’å¸§æ•°
    ï¼ˆå¯¹äºtaxi-v3å’Œfrozenlake-v1æˆ‘ä»¬ä½¿ç”¨1ï¼‰
    :param local_repo_path: æœ¬åœ°ä»“åº“çš„ä½ç½®
    """
    _, repo_name = repo_id.split("/")

    eval_env = env
    api = HfApi()

    # æ­¥éª¤1ï¼šåˆ›å»ºä»“åº“
    repo_url = api.create_repo(
        repo_id=repo_id,
        exist_ok=True,
    )

    # æ­¥éª¤2ï¼šä¸‹è½½æ–‡ä»¶
    repo_local_path = Path(snapshot_download(repo_id=repo_id))

    # æ­¥éª¤3ï¼šä¿å­˜æ¨¡å‹
    if env.spec.kwargs.get("map_name"):
        model["map_name"] = env.spec.kwargs.get("map_name")
        if env.spec.kwargs.get("is_slippery", "") == False:
            model["slippery"] = False

    # åºåˆ—åŒ–æ¨¡å‹
    with open((repo_local_path) / "q-learning.pkl", "wb") as f:
        pickle.dump(model, f)

    # æ­¥éª¤4ï¼šè¯„ä¼°æ¨¡å‹å¹¶æ„å»ºåŒ…å«è¯„ä¼°æŒ‡æ ‡çš„JSON
    mean_reward, std_reward = evaluate_agent(
        eval_env, model["max_steps"], model["n_eval_episodes"], model["qtable"], model["eval_seed"]
    )

    evaluate_data = {
        "env_id": model["env_id"],
        "mean_reward": mean_reward,
        "n_eval_episodes": model["n_eval_episodes"],
        "eval_datetime": datetime.datetime.now().isoformat(),
    }

    # å†™å…¥ä¸€ä¸ªåä¸º"results.json"çš„JSONæ–‡ä»¶ï¼Œå…¶ä¸­åŒ…å«
    # è¯„ä¼°ç»“æœ
    with open(repo_local_path / "results.json", "w") as outfile:
        json.dump(evaluate_data, outfile)

    # æ­¥éª¤5ï¼šåˆ›å»ºæ¨¡å‹å¡ç‰‡
    env_name = model["env_id"]
    if env.spec.kwargs.get("map_name"):
        env_name += "-" + env.spec.kwargs.get("map_name")

    if env.spec.kwargs.get("is_slippery", "") == False:
        env_name += "-" + "no_slippery"

    metadata = {}
    metadata["tags"] = [env_name, "q-learning", "reinforcement-learning", "custom-implementation"]

    # æ·»åŠ æŒ‡æ ‡
    eval = metadata_eval_result(
        model_pretty_name=repo_name,
        task_pretty_name="reinforcement-learning",
        task_id="reinforcement-learning",
        metrics_pretty_name="mean_reward",
        metrics_id="mean_reward",
        metrics_value=f"{mean_reward:.2f} +/- {std_reward:.2f}",
        dataset_pretty_name=env_name,
        dataset_id=env_name,
    )

    # åˆå¹¶ä¸¤ä¸ªå­—å…¸
    metadata = {**metadata, **eval}


    model_card = f"""
  # **Q-Learning**æ™ºèƒ½ä½“ç©**{env_id}**
  è¿™æ˜¯ä¸€ä¸ªè®­ç»ƒå¥½çš„**Q-Learning**æ™ºèƒ½ä½“ï¼Œå¯ä»¥ç©**{env_id}**ã€‚

  ## ä½¿ç”¨æ–¹æ³•

  model = load_from_hub(repo_id="{repo_id}", filename="q-learning.pkl")

  # ä¸è¦å¿˜è®°æ£€æŸ¥æ˜¯å¦éœ€è¦æ·»åŠ é¢å¤–çš„å±æ€§ï¼ˆis_slippery=Falseç­‰ï¼‰
  env = gym.make(model["env_id"])
  """

    evaluate_agent(env, model["max_steps"], model["n_eval_episodes"], model["qtable"], model["eval_seed"])

    readme_path = repo_local_path / "README.md"
    readme = ""
    print(readme_path.exists())
    if readme_path.exists():
        with readme_path.open("r", encoding="utf8") as f:
            readme = f.read()
    else:
        readme = model_card

    with readme_path.open("w", encoding="utf-8") as f:
        f.write(readme)

    # å°†æˆ‘ä»¬çš„æŒ‡æ ‡ä¿å­˜åˆ°Readmeå…ƒæ•°æ®
    metadata_save(readme_path, metadata)

    # æ­¥éª¤6ï¼šå½•åˆ¶è§†é¢‘
    video_path = repo_local_path / "replay.mp4"
    record_video(env, model["qtable"], video_path, video_fps)

    # æ­¥éª¤7ï¼šå°†æ‰€æœ‰å†…å®¹æ¨é€åˆ°Hub
    api.upload_folder(
        repo_id=repo_id,
        folder_path=repo_local_path,
        path_in_repo=".",
    )

    print("ä½ çš„æ¨¡å‹å·²æ¨é€åˆ°Hubã€‚ä½ å¯ä»¥åœ¨è¿™é‡ŒæŸ¥çœ‹ä½ çš„æ¨¡å‹ï¼š", repo_url)
```

### .

é€šè¿‡ä½¿ç”¨`push_to_hub`ï¼Œ**ä½ å¯ä»¥è¯„ä¼°ã€è®°å½•å›æ”¾ã€ç”Ÿæˆæ™ºèƒ½ä½“çš„æ¨¡å‹å¡ç‰‡å¹¶å°†å…¶æ¨é€åˆ°Hub**ã€‚

è¿™æ ·ï¼š
- ä½ å¯ä»¥**å±•ç¤ºæˆ‘ä»¬çš„å·¥ä½œ** ğŸ”¥
- ä½ å¯ä»¥**å¯è§†åŒ–ä½ çš„æ™ºèƒ½ä½“çš„æ¸¸æˆè¿‡ç¨‹** ğŸ‘€
- ä½ å¯ä»¥**ä¸ç¤¾åŒºåˆ†äº«ä¸€ä¸ªå…¶ä»–äººå¯ä»¥ä½¿ç”¨çš„æ™ºèƒ½ä½“** ğŸ’¾
- ä½ å¯ä»¥**è®¿é—®æ’è¡Œæ¦œ ğŸ† æŸ¥çœ‹ä½ çš„æ™ºèƒ½ä½“ä¸åŒå­¦ç›¸æ¯”è¡¨ç°å¦‚ä½•** ğŸ‘‰ https://huggingface.co/spaces/huggingface-projects/Deep-Reinforcement-Learning-Leaderboard


è¦èƒ½å¤Ÿä¸ç¤¾åŒºåˆ†äº«ä½ çš„æ¨¡å‹ï¼Œè¿˜éœ€è¦éµå¾ªä»¥ä¸‹ä¸‰ä¸ªæ­¥éª¤ï¼š

1ï¸âƒ£ ï¼ˆå¦‚æœå°šæœªå®Œæˆï¼‰åˆ›å»ºä¸€ä¸ªHFè´¦æˆ· â¡ https://huggingface.co/join

2ï¸âƒ£ ç™»å½•ï¼Œç„¶åï¼Œä½ éœ€è¦ä»Hugging Faceç½‘ç«™å­˜å‚¨ä½ çš„è®¤è¯ä»¤ç‰Œã€‚
- åˆ›å»ºä¸€ä¸ªæ–°ä»¤ç‰Œï¼ˆhttps://huggingface.co/settings/tokensï¼‰**å…·æœ‰å†™å…¥æƒé™**


<img src="https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/notebooks/create-token.jpg" alt="åˆ›å»ºHFä»¤ç‰Œ" />



```python
from huggingface_hub import notebook_login

notebook_login()
```

å¦‚æœä½ ä¸æƒ³ä½¿ç”¨Google Colabæˆ–Jupyter Notebookï¼Œä½ éœ€è¦ä½¿ç”¨è¿™ä¸ªå‘½ä»¤ä»£æ›¿ï¼š`huggingface-cli login`ï¼ˆæˆ–`login`ï¼‰

3ï¸âƒ£ æˆ‘ä»¬ç°åœ¨å‡†å¤‡ä½¿ç”¨`push_to_hub()`å‡½æ•°å°†æˆ‘ä»¬è®­ç»ƒå¥½çš„æ™ºèƒ½ä½“æ¨é€åˆ°ğŸ¤— Hub ğŸ”¥

- è®©æˆ‘ä»¬åˆ›å»º**åŒ…å«è¶…å‚æ•°å’ŒQè¡¨çš„æ¨¡å‹å­—å…¸**ã€‚

```python
model = {
    "env_id": env_id,
    "max_steps": max_steps,
    "n_training_episodes": n_training_episodes,
    "n_eval_episodes": n_eval_episodes,
    "eval_seed": eval_seed,
    "learning_rate": learning_rate,
    "gamma": gamma,
    "max_epsilon": max_epsilon,
    "min_epsilon": min_epsilon,
    "decay_rate": decay_rate,
    "qtable": Qtable_frozenlake,
}
```

è®©æˆ‘ä»¬å¡«å†™`push_to_hub`å‡½æ•°ï¼š

- `repo_id`ï¼šå°†åˆ›å»º/æ›´æ–°çš„Hugging Face Hubä»“åº“çš„åç§°`
(repo_id = {username}/{repo_name})`
ğŸ’¡ ä¸€ä¸ªå¥½çš„`repo_id`æ˜¯`{username}/q-{env_id}`
- `model`ï¼šåŒ…å«è¶…å‚æ•°å’ŒQè¡¨çš„æ¨¡å‹å­—å…¸ã€‚
- `env`ï¼šç¯å¢ƒã€‚
- `commit_message`ï¼šæäº¤ä¿¡æ¯

```python
model
```

```python
username = ""  # å¡«å†™æ­¤å¤„
repo_name = "q-FrozenLake-v1-4x4-noSlippery"
push_to_hub(repo_id=f"{username}/{repo_name}", model=model, env=env)
```

æ­å–œ ğŸ¥³ ä½ åˆšåˆšä»å¤´å®ç°ã€è®­ç»ƒå¹¶ä¸Šä¼ äº†ä½ çš„ç¬¬ä¸€ä¸ªå¼ºåŒ–å­¦ä¹ æ™ºèƒ½ä½“ã€‚
FrozenLake-v1 no_slipperyæ˜¯ä¸€ä¸ªéå¸¸ç®€å•çš„ç¯å¢ƒï¼Œè®©æˆ‘ä»¬å°è¯•ä¸€ä¸ªæ›´éš¾çš„ç¯å¢ƒ ğŸ”¥ã€‚

# ç¬¬2éƒ¨åˆ†ï¼šTaxi-v3 ğŸš–

## åˆ›å»ºå¹¶ç†è§£[Taxi-v3 ğŸš•](https://gymnasium.farama.org/environments/toy_text/taxi/)
---

ğŸ’¡ å½“ä½ å¼€å§‹ä½¿ç”¨ä¸€ä¸ªç¯å¢ƒæ—¶ï¼Œä¸€ä¸ªå¥½ä¹ æƒ¯æ˜¯æŸ¥çœ‹å…¶æ–‡æ¡£

ğŸ‘‰ https://gymnasium.farama.org/environments/toy_text/taxi/

---

åœ¨`Taxi-v3` ğŸš•ä¸­ï¼Œç½‘æ ¼ä¸–ç•Œä¸­æœ‰å››ä¸ªæŒ‡å®šä½ç½®ï¼Œåˆ†åˆ«ç”¨R(ed)ã€G(reen)ã€Y(ellow)å’ŒB(lue)è¡¨ç¤ºã€‚

å½“å›åˆå¼€å§‹æ—¶ï¼Œ**å‡ºç§Ÿè½¦ä»ä¸€ä¸ªéšæœºæ–¹æ ¼å¼€å§‹**ï¼Œä¹˜å®¢åœ¨ä¸€ä¸ªéšæœºä½ç½®ã€‚å‡ºç§Ÿè½¦é©¶å‘ä¹˜å®¢çš„ä½ç½®ï¼Œ**æ¥ä¸Šä¹˜å®¢**ï¼Œé©¶å‘ä¹˜å®¢çš„ç›®çš„åœ°ï¼ˆå››ä¸ªæŒ‡å®šä½ç½®ä¸­çš„å¦ä¸€ä¸ªï¼‰ï¼Œç„¶å**æ”¾ä¸‹ä¹˜å®¢**ã€‚ä¸€æ—¦ä¹˜å®¢è¢«æ”¾ä¸‹ï¼Œå›åˆç»“æŸã€‚


<img src="https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/notebooks/unit2/taxi.png" alt="Taxi" />


```python
env = gym.make("Taxi-v3", render_mode="rgb_array")
```

**ç”±äºæœ‰25ä¸ªå‡ºç§Ÿè½¦ä½ç½®ï¼Œ5ä¸ªå¯èƒ½çš„ä¹˜å®¢ä½ç½®**ï¼ˆåŒ…æ‹¬ä¹˜å®¢åœ¨å‡ºç§Ÿè½¦ä¸­çš„æƒ…å†µï¼‰ï¼Œä»¥åŠ**4ä¸ªç›®çš„åœ°ä½ç½®**ï¼Œæ‰€ä»¥æœ‰**500ä¸ªç¦»æ•£çŠ¶æ€**ã€‚


```python
state_space = env.observation_space.n
print("æœ‰ ", state_space, " ä¸ªå¯èƒ½çš„çŠ¶æ€")
```

```python
action_space = env.action_space.n
print("æœ‰ ", action_space, " ä¸ªå¯èƒ½çš„åŠ¨ä½œ")
```

åŠ¨ä½œç©ºé—´ï¼ˆæ™ºèƒ½ä½“å¯ä»¥é‡‡å–çš„å¯èƒ½åŠ¨ä½œé›†ï¼‰æ˜¯ç¦»æ•£çš„ï¼Œæœ‰**6ä¸ªå¯ç”¨åŠ¨ä½œ ğŸ®**ï¼š

- 0: å‘å—ç§»åŠ¨
- 1: å‘åŒ—ç§»åŠ¨
- 2: å‘ä¸œç§»åŠ¨
- 3: å‘è¥¿ç§»åŠ¨
- 4: æ¥ä¹˜å®¢
- 5: æ”¾ä¸‹ä¹˜å®¢

å¥–åŠ±å‡½æ•° ğŸ’°ï¼š

- æ¯æ­¥-1ï¼Œé™¤éè§¦å‘å…¶ä»–å¥–åŠ±ã€‚
- é€è¾¾ä¹˜å®¢+20ã€‚
- éæ³•æ‰§è¡Œ"æ¥å®¢"å’Œ"æ”¾å®¢"åŠ¨ä½œ-10ã€‚

```python
# åˆ›å»ºæˆ‘ä»¬çš„Qè¡¨ï¼Œæœ‰state_sizeè¡Œå’Œaction_sizeåˆ—ï¼ˆ500x6ï¼‰
Qtable_taxi = initialize_q_table(state_space, action_space)
print(Qtable_taxi)
print("Qè¡¨å½¢çŠ¶ï¼š", Qtable_taxi.shape)
```

## å®šä¹‰è¶…å‚æ•° âš™ï¸

âš  è¯·å‹¿ä¿®æ”¹EVAL_SEEDï¼ševal_seedæ•°ç»„**å…è®¸æˆ‘ä»¬ä½¿ç”¨ä¸æ¯ä½åŒå­¦ç›¸åŒçš„å‡ºç§Ÿè½¦èµ·å§‹ä½ç½®æ¥è¯„ä¼°ä½ çš„æ™ºèƒ½ä½“**

```python
# è®­ç»ƒå‚æ•°
n_training_episodes = 25000  # æ€»è®­ç»ƒå›åˆæ•°
learning_rate = 0.7  # å­¦ä¹ ç‡

# è¯„ä¼°å‚æ•°
n_eval_episodes = 100  # æµ‹è¯•å›åˆæ€»æ•°

# è¯·å‹¿ä¿®æ”¹EVAL_SEED
eval_seed = [
    16,
    54,
    165,
    177,
    191,
    191,
    120,
    80,
    149,
    178,
    48,
    38,
    6,
    125,
    174,
    73,
    50,
    172,
    100,
    148,
    146,
    6,
    25,
    40,
    68,
    148,
    49,
    167,
    9,
    97,
    164,
    176,
    61,
    7,
    54,
    55,
    161,
    131,
    184,
    51,
    170,
    12,
    120,
    113,
    95,
    126,
    51,
    98,
    36,
    135,
    54,
    82,
    45,
    95,
    89,
    59,
    95,
    124,
    9,
    113,
    58,
    85,
    51,
    134,
    121,
    169,
    105,
    21,
    30,
    11,
    50,
    65,
    12,
    43,
    82,
    145,
    152,
    97,
    106,
    55,
    31,
    85,
    38,
    112,
    102,
    168,
    123,
    97,
    21,
    83,
    158,
    26,
    80,
    63,
    5,
    81,
    32,
    11,
    28,
    148,
]  # è¯„ä¼°ç§å­ï¼Œè¿™ç¡®ä¿æ‰€æœ‰åŒå­¦çš„æ™ºèƒ½ä½“éƒ½åœ¨ç›¸åŒçš„å‡ºç§Ÿè½¦èµ·å§‹ä½ç½®ä¸Šè®­ç»ƒ
# æ¯ä¸ªç§å­éƒ½æœ‰ä¸€ä¸ªç‰¹å®šçš„èµ·å§‹çŠ¶æ€

# ç¯å¢ƒå‚æ•°
env_id = "Taxi-v3"  # ç¯å¢ƒåç§°
max_steps = 99  # æ¯å›åˆæœ€å¤§æ­¥æ•°
gamma = 0.95  # æŠ˜æ‰£ç‡

# æ¢ç´¢å‚æ•°
max_epsilon = 1.0  # å¼€å§‹æ—¶çš„æ¢ç´¢æ¦‚ç‡
min_epsilon = 0.05  # æœ€å°æ¢ç´¢æ¦‚ç‡
decay_rate = 0.005  # æ¢ç´¢æ¦‚ç‡çš„æŒ‡æ•°è¡°å‡ç‡
```

## è®­ç»ƒæˆ‘ä»¬çš„Q-Learningæ™ºèƒ½ä½“ ğŸƒ

```python
Qtable_taxi = train(n_training_episodes, min_epsilon, max_epsilon, decay_rate, env, max_steps, Qtable_taxi)
Qtable_taxi
```

## åˆ›å»ºæ¨¡å‹å­—å…¸ ğŸ’¾ å¹¶å°†æˆ‘ä»¬è®­ç»ƒå¥½çš„æ¨¡å‹å‘å¸ƒåˆ°Hub ğŸ”¥

- æˆ‘ä»¬åˆ›å»ºä¸€ä¸ªæ¨¡å‹å­—å…¸ï¼Œå…¶ä¸­åŒ…å«æ‰€æœ‰è®­ç»ƒè¶…å‚æ•°ï¼ˆä¸ºäº†å¯é‡ç°æ€§ï¼‰å’ŒQè¡¨ã€‚


```python
model = {
    "env_id": env_id,
    "max_steps": max_steps,
    "n_training_episodes": n_training_episodes,
    "n_eval_episodes": n_eval_episodes,
    "eval_seed": eval_seed,
    "learning_rate": learning_rate,
    "gamma": gamma,
    "max_epsilon": max_epsilon,
    "min_epsilon": min_epsilon,
    "decay_rate": decay_rate,
    "qtable": Qtable_taxi,
}
```

```python
username = ""  # å¡«å†™æ­¤å¤„
repo_name = ""  # å¡«å†™æ­¤å¤„
push_to_hub(repo_id=f"{username}/{repo_name}", model=model, env=env)
```

ç°åœ¨å®ƒå·²ç»åœ¨Hubä¸Šäº†ï¼Œä½ å¯ä»¥ä½¿ç”¨æ’è¡Œæ¦œ ğŸ† æ¯”è¾ƒä½ çš„Taxi-v3ä¸åŒå­¦ä»¬çš„ç»“æœ ğŸ‘‰ https://huggingface.co/spaces/huggingface-projects/Deep-Reinforcement-Learning-Leaderboard


<img src="https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/notebooks/unit2/taxi-leaderboard.png" alt="Taxi Leaderboard" />

# ç¬¬3éƒ¨åˆ†ï¼šä»HubåŠ è½½ ğŸ”½

Hugging Face Hub ğŸ¤— çš„ä¸€ä¸ªä»¤äººæƒŠå¹ä¹‹å¤„æ˜¯ä½ å¯ä»¥è½»æ¾åœ°ä»ç¤¾åŒºåŠ è½½å¼ºå¤§çš„æ¨¡å‹ã€‚

ä»HubåŠ è½½ä¿å­˜çš„æ¨¡å‹éå¸¸ç®€å•ï¼š

1. ä½ å‰å¾€ https://huggingface.co/models?other=q-learning æŸ¥çœ‹æ‰€æœ‰ä¿å­˜çš„q-learningæ¨¡å‹åˆ—è¡¨ã€‚
2. é€‰æ‹©ä¸€ä¸ªå¹¶å¤åˆ¶å…¶repo_id

<img src="https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/notebooks/unit2/copy-id.png" alt="Copy id" />

3. ç„¶åæˆ‘ä»¬åªéœ€è¦ä½¿ç”¨`load_from_hub`ï¼Œæä¾›ï¼š
- repo_id
- filenameï¼šä»“åº“å†…ä¿å­˜çš„æ¨¡å‹ã€‚

#### è¯·å‹¿ä¿®æ”¹æ­¤ä»£ç 

```python
from urllib.error import HTTPError

from huggingface_hub import hf_hub_download


def load_from_hub(repo_id: str, filename: str) -> str:
    """
    ä»Hugging Face Hubä¸‹è½½æ¨¡å‹ã€‚
    :param repo_id: Hugging Face Hubä¸Šæ¨¡å‹ä»“åº“çš„id
    :param filename: ä»“åº“ä¸­æ¨¡å‹zipæ–‡ä»¶çš„åç§°
    """
    # ä»Hubè·å–æ¨¡å‹ï¼Œä¸‹è½½å¹¶ç¼“å­˜æ¨¡å‹åˆ°æœ¬åœ°ç£ç›˜
    pickle_model = hf_hub_download(repo_id=repo_id, filename=filename)

    with open(pickle_model, "rb") as f:
        downloaded_model_file = pickle.load(f)

    return downloaded_model_file
```

### .

```python
model = load_from_hub(repo_id="ThomasSimonini/q-Taxi-v3", filename="q-learning.pkl")  # å°è¯•ä½¿ç”¨å¦ä¸€ä¸ªæ¨¡å‹

print(model)
env = gym.make(model["env_id"])

evaluate_agent(env, model["max_steps"], model["n_eval_episodes"], model["qtable"], model["eval_seed"])
```

```python
model = load_from_hub(
    repo_id="ThomasSimonini/q-FrozenLake-v1-no-slippery", filename="q-learning.pkl"
)  # å°è¯•ä½¿ç”¨å¦ä¸€ä¸ªæ¨¡å‹

env = gym.make(model["env_id"], is_slippery=False)

evaluate_agent(env, model["max_steps"], model["n_eval_episodes"], model["qtable"], model["eval_seed"])
```

## ä¸€äº›é¢å¤–çš„æŒ‘æˆ˜ ğŸ†

å­¦ä¹ çš„æœ€ä½³æ–¹å¼**æ˜¯è‡ªå·±å°è¯•**ï¼æ­£å¦‚ä½ æ‰€çœ‹åˆ°çš„ï¼Œå½“å‰çš„æ™ºèƒ½ä½“è¡¨ç°ä¸æ˜¯å¾ˆå¥½ã€‚ä½œä¸ºç¬¬ä¸€ä¸ªå»ºè®®ï¼Œä½ å¯ä»¥è®­ç»ƒæ›´å¤šæ­¥éª¤ã€‚ä½¿ç”¨1,000,000æ­¥ï¼Œæˆ‘ä»¬çœ‹åˆ°äº†ä¸€äº›å¾ˆå¥½çš„ç»“æœï¼

åœ¨[æ’è¡Œæ¦œ](https://huggingface.co/spaces/huggingface-projects/Deep-Reinforcement-Learning-Leaderboard)ä¸­ï¼Œä½ ä¼šæ‰¾åˆ°ä½ çš„æ™ºèƒ½ä½“ã€‚ä½ èƒ½ç™»ä¸Šæ¦œé¦–å—ï¼Ÿ

ä»¥ä¸‹æ˜¯ä¸€äº›æ”€ç™»æ’è¡Œæ¦œçš„æƒ³æ³•ï¼š

* è®­ç»ƒæ›´å¤šæ­¥éª¤
* é€šè¿‡æŸ¥çœ‹åŒå­¦ä»¬çš„åšæ³•ï¼Œå°è¯•ä¸åŒçš„è¶…å‚æ•°ã€‚
* **å°†ä½ æ–°è®­ç»ƒçš„æ¨¡å‹**æ¨é€åˆ°Hub ğŸ”¥

åœ¨å†°é¢ä¸Šè¡Œèµ°å’Œé©¾é©¶å‡ºç§Ÿè½¦å¯¹ä½ æ¥è¯´å¤ªæ— èŠäº†å—ï¼Ÿå°è¯•**æ”¹å˜ç¯å¢ƒ**ï¼Œä¸ºä»€ä¹ˆä¸ä½¿ç”¨FrozenLake-v1æ»‘åŠ¨ç‰ˆæœ¬ï¼ŸæŸ¥çœ‹å®ƒä»¬å¦‚ä½•å·¥ä½œ[ä½¿ç”¨gymnasiumæ–‡æ¡£](https://gymnasium.farama.org/)å¹¶äº«å—ä¹è¶£ ğŸ‰ã€‚

_____________________________________________________________________
æ­å–œ ğŸ¥³ï¼Œä½ åˆšåˆšå®ç°ã€è®­ç»ƒå¹¶ä¸Šä¼ äº†ä½ çš„ç¬¬ä¸€ä¸ªå¼ºåŒ–å­¦ä¹ æ™ºèƒ½ä½“ã€‚

ç†è§£Q-Learningæ˜¯**ç†è§£åŸºäºä»·å€¼çš„æ–¹æ³•çš„é‡è¦ä¸€æ­¥ã€‚**

åœ¨ä¸‹ä¸€ä¸ªå•å…ƒçš„æ·±åº¦Q-Learningä¸­ï¼Œæˆ‘ä»¬å°†çœ‹åˆ°ï¼Œè™½ç„¶åˆ›å»ºå’Œæ›´æ–°Qè¡¨æ˜¯ä¸€ä¸ªå¥½ç­–ç•¥â€”â€”**ä½†å®ƒä¸å…·æœ‰å¯æ‰©å±•æ€§ã€‚**

ä¾‹å¦‚ï¼Œæƒ³è±¡ä½ åˆ›å»ºäº†ä¸€ä¸ªå­¦ä¹ ç©Doomçš„æ™ºèƒ½ä½“ã€‚

<img src="https://vizdoom.cs.put.edu.pl/user/pages/01.tutorial/basic.png" alt="Doom"/>

Doomæ˜¯ä¸€ä¸ªå…·æœ‰å·¨å¤§çŠ¶æ€ç©ºé—´ï¼ˆæ•°ç™¾ä¸‡ä¸ªä¸åŒçŠ¶æ€ï¼‰çš„å¤§å‹ç¯å¢ƒã€‚ä¸ºè¯¥ç¯å¢ƒåˆ›å»ºå’Œæ›´æ–°Qè¡¨å°†ä¸ä¼šé«˜æ•ˆã€‚

è¿™å°±æ˜¯ä¸ºä»€ä¹ˆæˆ‘ä»¬å°†åœ¨ä¸‹ä¸€ä¸ªå•å…ƒä¸­å­¦ä¹ æ·±åº¦Q-Learningï¼Œè¿™æ˜¯ä¸€ç§ç®—æ³•ï¼Œ**å…¶ä¸­æˆ‘ä»¬ä½¿ç”¨ç¥ç»ç½‘ç»œæ¥è¿‘ä¼¼ï¼Œç»™å®šä¸€ä¸ªçŠ¶æ€ï¼Œæ¯ä¸ªåŠ¨ä½œçš„ä¸åŒQå€¼ã€‚**

<img src="https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit4/atari-envs.gif" alt="Environments"/>


æˆ‘ä»¬åœ¨ç¬¬3å•å…ƒè§ï¼ ğŸ”¥

## æŒç»­å­¦ä¹ ï¼Œä¿æŒç²¾å½© ğŸ¤—
