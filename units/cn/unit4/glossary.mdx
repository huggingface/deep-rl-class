# 术语表 

这是一个社区创建的术语表。欢迎贡献！

- **深度Q学习：** 一种基于价值的深度强化学习算法，使用深度神经网络来近似给定状态下动作的Q值。深度Q学习的目标是通过学习动作值来找到最大化预期累积奖励的最优策略。

- **基于价值的方法：** 通过估计价值函数作为寻找最优策略的中间步骤的强化学习方法。

- **基于策略的方法：** 不学习价值函数而直接学习近似最优策略的强化学习方法。在实践中，它们输出动作的概率分布。 

    使用策略梯度方法而非基于价值的方法的好处包括： 
    - 集成的简单性：无需存储动作值；
    - 学习随机策略的能力：智能体在探索状态空间时不会总是采取相同的轨迹，并避免感知混叠问题；
    - 在高维和连续动作空间中的有效性；以及
    - 改进的收敛特性。

- **策略梯度：** 基于策略方法的一个子集，其目标是使用梯度上升最大化参数化策略的性能。策略梯度的目标是通过调整策略使好的动作（最大化回报的动作）在未来被更频繁地采样，从而控制动作的概率分布。 

- **蒙特卡洛Reinforce：** 一种策略梯度算法，使用整个回合的估计回报来更新策略参数。

如果你想改进课程，你可以[提交Pull Request。](https://github.com/huggingface/deep-rl-class/pulls)

这个术语表的实现要感谢：

- [Diego Carpintero](https://github.com/dcarpintero)