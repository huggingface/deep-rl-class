# ä½¿ç”¨Panda-Gymæœºå™¨äººæ¨¡æ‹Ÿç¯å¢ƒçš„ä¼˜åŠ¿æ¼”å‘˜è¯„è®ºå®¶ç®—æ³•(A2C) ğŸ¤– [[hands-on]]


      <CourseFloatingBanner classNames="absolute z-10 right-0 top-0"
      notebooks={[
        {label: "Google Colab", value: "https://colab.research.google.com/github/huggingface/deep-rl-class/blob/main/notebooks/unit6/unit6.ipynb"}
        ]}
        askForHelpUrl="http://hf.co/join/discord" />


ç°åœ¨ä½ å·²ç»å­¦ä¹ äº†ä¼˜åŠ¿æ¼”å‘˜è¯„è®ºå®¶ç®—æ³•(A2C)èƒŒåçš„ç†è®ºï¼Œ**ä½ å·²ç»å‡†å¤‡å¥½ä½¿ç”¨Stable-Baselines3åœ¨æœºå™¨äººç¯å¢ƒä¸­è®­ç»ƒä½ çš„A2Cæ™ºèƒ½ä½“**ã€‚å¹¶è®­ç»ƒï¼š
- ä¸€ä¸ªæœºå™¨äººæ‰‹è‡‚ ğŸ¦¾ ç§»åŠ¨åˆ°æ­£ç¡®ä½ç½®ã€‚

æˆ‘ä»¬å°†ä½¿ç”¨ï¼š
- [panda-gym](https://github.com/qgallouedec/panda-gym)

ä¸ºäº†åœ¨è®¤è¯è¿‡ç¨‹ä¸­éªŒè¯è¿™ä¸ªå®è·µç»ƒä¹ ï¼Œä½ éœ€è¦å°†ä½ è®­ç»ƒçš„ä¸¤ä¸ªæ¨¡å‹æ¨é€åˆ°Hubå¹¶è·å¾—ä»¥ä¸‹ç»“æœï¼š

- `PandaReachDense-v3` è·å¾— >= -3.5 çš„ç»“æœã€‚

è¦æŸ¥æ‰¾ä½ çš„ç»“æœï¼Œ[å‰å¾€æ’è¡Œæ¦œ](https://huggingface.co/spaces/huggingface-projects/Deep-Reinforcement-Learning-Leaderboard)å¹¶æ‰¾åˆ°ä½ çš„æ¨¡å‹ï¼Œ**ç»“æœ = å¹³å‡å¥–åŠ± - å¥–åŠ±çš„æ ‡å‡†å·®**

æœ‰å…³è®¤è¯è¿‡ç¨‹çš„æ›´å¤šä¿¡æ¯ï¼Œè¯·æŸ¥çœ‹æ­¤éƒ¨åˆ† ğŸ‘‰ https://huggingface.co/deep-rl-course/en/unit0/introduction#certification-process

**è¦å¼€å§‹å®è·µï¼Œè¯·ç‚¹å‡»"åœ¨Colabä¸­æ‰“å¼€"æŒ‰é’®** ğŸ‘‡ :

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/huggingface/deep-rl-class/blob/master/notebooks/unit6/unit6.ipynb)


# å•å…ƒ6ï¼šä½¿ç”¨Panda-Gymæœºå™¨äººæ¨¡æ‹Ÿç¯å¢ƒçš„ä¼˜åŠ¿æ¼”å‘˜è¯„è®ºå®¶ç®—æ³•(A2C) ğŸ¤–

### ğŸ® ç¯å¢ƒï¼š

- [Panda-Gym](https://github.com/qgallouedec/panda-gym)

### ğŸ“š å¼ºåŒ–å­¦ä¹ åº“ï¼š

- [Stable-Baselines3](https://stable-baselines3.readthedocs.io/)

æˆ‘ä»¬ä¸€ç›´åœ¨åŠªåŠ›æ”¹è¿›æˆ‘ä»¬çš„æ•™ç¨‹ï¼Œæ‰€ä»¥**å¦‚æœä½ åœ¨è¿™ä¸ªç¬”è®°æœ¬ä¸­å‘ç°ä¸€äº›é—®é¢˜**ï¼Œè¯·[åœ¨GitHubä»“åº“ä¸Šæå‡ºissue](https://github.com/huggingface/deep-rl-class/issues)ã€‚

## æœ¬ç¬”è®°æœ¬çš„ç›®æ ‡ ğŸ†

åœ¨å®Œæˆæœ¬ç¬”è®°æœ¬åï¼Œä½ å°†ï¼š

- èƒ½å¤Ÿä½¿ç”¨**Panda-Gym**ç¯å¢ƒåº“ã€‚
- èƒ½å¤Ÿ**ä½¿ç”¨A2Cè®­ç»ƒæœºå™¨äºº**ã€‚
- ç†è§£**ä¸ºä»€ä¹ˆæˆ‘ä»¬éœ€è¦å¯¹è¾“å…¥è¿›è¡Œæ ‡å‡†åŒ–**ã€‚
- èƒ½å¤Ÿ**å°†ä½ è®­ç»ƒçš„æ™ºèƒ½ä½“å’Œä»£ç æ¨é€åˆ°Hub**ï¼Œå¹¶é™„å¸¦ç²¾ç¾çš„è§†é¢‘å›æ”¾å’Œè¯„ä¼°åˆ†æ•° ğŸ”¥ã€‚

## å…ˆå†³æ¡ä»¶ ğŸ—ï¸

åœ¨æ·±å…¥å­¦ä¹ æœ¬ç¬”è®°æœ¬ä¹‹å‰ï¼Œä½ éœ€è¦ï¼š

ğŸ”² ğŸ“š é€šè¿‡[é˜…è¯»å•å…ƒ6](https://huggingface.co/deep-rl-course/unit6/introduction)å­¦ä¹ æ¼”å‘˜è¯„è®ºå®¶æ–¹æ³• ğŸ¤—

# è®©æˆ‘ä»¬è®­ç»ƒæˆ‘ä»¬çš„ç¬¬ä¸€ä¸ªæœºå™¨äºº ğŸ¤–

## è®¾ç½®GPU ğŸ’ª

- ä¸ºäº†**åŠ é€Ÿæ™ºèƒ½ä½“çš„è®­ç»ƒï¼Œæˆ‘ä»¬å°†ä½¿ç”¨GPU**ã€‚è¦åšåˆ°è¿™ä¸€ç‚¹ï¼Œè¯·è½¬åˆ°`Runtime > Change Runtime type`

<img src="https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/notebooks/gpu-step1.jpg" alt="GPUæ­¥éª¤1" />

- `Hardware Accelerator > GPU`

<img src="https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/notebooks/gpu-step2.jpg" alt="GPUæ­¥éª¤2" />

## åˆ›å»ºè™šæ‹Ÿæ˜¾ç¤ºå™¨ ğŸ”½

åœ¨ç¬”è®°æœ¬ä¸­ï¼Œæˆ‘ä»¬éœ€è¦ç”Ÿæˆå›æ”¾è§†é¢‘ã€‚ä¸ºæ­¤ï¼Œåœ¨colabä¸­ï¼Œ**æˆ‘ä»¬éœ€è¦æœ‰ä¸€ä¸ªè™šæ‹Ÿå±å¹•æ¥èƒ½å¤Ÿæ¸²æŸ“ç¯å¢ƒ**ï¼ˆä»è€Œè®°å½•å¸§ï¼‰ã€‚

ä»¥ä¸‹å•å…ƒå°†å®‰è£…åº“å¹¶åˆ›å»ºå¹¶è¿è¡Œè™šæ‹Ÿå±å¹• ğŸ–¥

```python
%%capture
!apt install python-opengl
!apt install ffmpeg
!apt install xvfb
!pip3 install pyvirtualdisplay
```

```python
# è™šæ‹Ÿæ˜¾ç¤ºå™¨
from pyvirtualdisplay import Display

virtual_display = Display(visible=0, size=(1400, 900))
virtual_display.start()
```

### å®‰è£…ä¾èµ–é¡¹ ğŸ”½

æˆ‘ä»¬å°†å®‰è£…å¤šä¸ªä¾èµ–é¡¹ï¼š

- `gymnasium`
- `panda-gym`ï¼šåŒ…å«æœºå™¨äººæ‰‹è‡‚ç¯å¢ƒã€‚
- `stable-baselines3`ï¼šSB3æ·±åº¦å¼ºåŒ–å­¦ä¹ åº“ã€‚
- `huggingface_sb3`ï¼šStable-baselines3çš„é™„åŠ ä»£ç ï¼Œç”¨äºä»Hugging Face ğŸ¤— HubåŠ è½½å’Œä¸Šä¼ æ¨¡å‹ã€‚
- `huggingface_hub`ï¼šå…è®¸ä»»ä½•äººä½¿ç”¨Hubä»“åº“çš„åº“ã€‚

```bash
!pip install stable-baselines3[extra]
!pip install gymnasium
!pip install huggingface_sb3
!pip install huggingface_hub
!pip install panda_gym
```

## å¯¼å…¥åŒ… ğŸ“¦

```python
import os

import gymnasium as gym
import panda_gym

from huggingface_sb3 import load_from_hub, package_to_hub

from stable_baselines3 import A2C
from stable_baselines3.common.evaluation import evaluate_policy
from stable_baselines3.common.vec_env import DummyVecEnv, VecNormalize
from stable_baselines3.common.env_util import make_vec_env

from huggingface_hub import notebook_login
```

## PandaReachDense-v3 ğŸ¦¾

æˆ‘ä»¬å°†è¦è®­ç»ƒçš„æ™ºèƒ½ä½“æ˜¯ä¸€ä¸ªéœ€è¦è¿›è¡Œæ§åˆ¶ï¼ˆç§»åŠ¨æ‰‹è‡‚å’Œä½¿ç”¨æœ«ç«¯æ‰§è¡Œå™¨ï¼‰çš„æœºå™¨äººæ‰‹è‡‚ã€‚

åœ¨æœºå™¨äººå­¦ä¸­ï¼Œ*æœ«ç«¯æ‰§è¡Œå™¨*æ˜¯æœºå™¨äººæ‰‹è‡‚æœ«ç«¯çš„è®¾å¤‡ï¼Œè®¾è®¡ç”¨äºä¸ç¯å¢ƒäº¤äº’ã€‚

åœ¨`PandaReach`ä¸­ï¼Œæœºå™¨äººå¿…é¡»å°†å…¶æœ«ç«¯æ‰§è¡Œå™¨æ”¾ç½®åœ¨ç›®æ ‡ä½ç½®ï¼ˆç»¿è‰²çƒï¼‰ã€‚

æˆ‘ä»¬å°†ä½¿ç”¨è¿™ä¸ªç¯å¢ƒçš„å¯†é›†ç‰ˆæœ¬ã€‚è¿™æ„å‘³ç€æˆ‘ä»¬å°†è·å¾—ä¸€ä¸ª*å¯†é›†å¥–åŠ±å‡½æ•°*ï¼Œå®ƒ**å°†åœ¨æ¯ä¸ªæ—¶é—´æ­¥æä¾›å¥–åŠ±**ï¼ˆæ™ºèƒ½ä½“è¶Šæ¥è¿‘å®Œæˆä»»åŠ¡ï¼Œå¥–åŠ±è¶Šé«˜ï¼‰ã€‚ä¸*ç¨€ç–å¥–åŠ±å‡½æ•°*ç›¸åï¼Œåœ¨ç¨€ç–å¥–åŠ±å‡½æ•°ä¸­ï¼Œç¯å¢ƒ**å½“ä¸”ä»…å½“ä»»åŠ¡å®Œæˆæ—¶æ‰è¿”å›å¥–åŠ±**ã€‚

æ­¤å¤–ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨*æœ«ç«¯æ‰§è¡Œå™¨ä½ç§»æ§åˆ¶*ï¼Œè¿™æ„å‘³ç€**åŠ¨ä½œå¯¹åº”äºæœ«ç«¯æ‰§è¡Œå™¨çš„ä½ç§»**ã€‚æˆ‘ä»¬ä¸æ§åˆ¶æ¯ä¸ªå…³èŠ‚çš„ä¸ªåˆ«è¿åŠ¨ï¼ˆå…³èŠ‚æ§åˆ¶ï¼‰ã€‚

<img src="https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit8/robotics.jpg"  alt="æœºå™¨äººå­¦"/>

è¿™æ ·**è®­ç»ƒå°†æ›´å®¹æ˜“**ã€‚

### åˆ›å»ºç¯å¢ƒ

#### ç¯å¢ƒ ğŸ®

åœ¨`PandaReachDense-v3`ä¸­ï¼Œæœºå™¨äººæ‰‹è‡‚å¿…é¡»å°†å…¶æœ«ç«¯æ‰§è¡Œå™¨æ”¾ç½®åœ¨ç›®æ ‡ä½ç½®ï¼ˆç»¿è‰²çƒï¼‰ã€‚

```python
env_id = "PandaReachDense-v3"

# åˆ›å»ºç¯å¢ƒ
env = gym.make(env_id)

# è·å–çŠ¶æ€ç©ºé—´å’ŒåŠ¨ä½œç©ºé—´
s_size = env.observation_space.shape
a_size = env.action_space
```

```python
print("_____è§‚å¯Ÿç©ºé—´_____ \n")
print("çŠ¶æ€ç©ºé—´æ˜¯ï¼š", s_size)
print("è§‚å¯Ÿæ ·æœ¬", env.observation_space.sample()) # è·å–éšæœºè§‚å¯Ÿ
```

è§‚å¯Ÿç©ºé—´**æ˜¯ä¸€ä¸ªåŒ…å«3ä¸ªä¸åŒå…ƒç´ çš„å­—å…¸**ï¼š

- `achieved_goal`ï¼šç›®æ ‡çš„(x,y,z)ä½ç½®ã€‚
- `desired_goal`ï¼šç›®æ ‡ä½ç½®ä¸å½“å‰å¯¹è±¡ä½ç½®ä¹‹é—´çš„(x,y,z)è·ç¦»ã€‚
- `observation`ï¼šæœ«ç«¯æ‰§è¡Œå™¨çš„ä½ç½®(x,y,z)å’Œé€Ÿåº¦(vx, vy, vz)ã€‚

é‰´äºè§‚å¯Ÿæ˜¯ä¸€ä¸ªå­—å…¸ï¼Œ**æˆ‘ä»¬éœ€è¦ä½¿ç”¨MultiInputPolicyç­–ç•¥è€Œä¸æ˜¯MlpPolicy**ã€‚

```python
print("\n _____åŠ¨ä½œç©ºé—´_____ \n")
print("åŠ¨ä½œç©ºé—´æ˜¯ï¼š", a_size)
print("åŠ¨ä½œç©ºé—´æ ·æœ¬", env.action_space.sample()) # é‡‡å–éšæœºåŠ¨ä½œ
```

åŠ¨ä½œç©ºé—´æ˜¯ä¸€ä¸ªåŒ…å«3ä¸ªå€¼çš„å‘é‡ï¼š
- æ§åˆ¶x, y, zç§»åŠ¨


### æ ‡å‡†åŒ–è§‚å¯Ÿå’Œå¥–åŠ±

å¼ºåŒ–å­¦ä¹ ä¸­çš„ä¸€ä¸ªè‰¯å¥½å®è·µæ˜¯[æ ‡å‡†åŒ–è¾“å…¥ç‰¹å¾](https://stable-baselines3.readthedocs.io/en/master/guide/rl_tips.html)ã€‚

ä¸ºæ­¤ï¼Œæœ‰ä¸€ä¸ªåŒ…è£…å™¨å°†è®¡ç®—è¾“å…¥ç‰¹å¾çš„è¿è¡Œå¹³å‡å€¼å’Œæ ‡å‡†å·®ã€‚

æˆ‘ä»¬è¿˜é€šè¿‡æ·»åŠ `norm_reward = True`æ¥ä½¿ç”¨è¿™ä¸ªç›¸åŒçš„åŒ…è£…å™¨æ ‡å‡†åŒ–å¥–åŠ±

[ä½ åº”è¯¥æŸ¥çœ‹æ–‡æ¡£æ¥å¡«å†™è¿™ä¸ªå•å…ƒæ ¼](https://stable-baselines3.readthedocs.io/en/master/guide/vec_envs.html#vecnormalize)

```python
env = make_vec_env(env_id, n_envs=4)

# æ·»åŠ è¿™ä¸ªåŒ…è£…å™¨æ¥æ ‡å‡†åŒ–è§‚å¯Ÿå’Œå¥–åŠ±
env = # TODO: æ·»åŠ åŒ…è£…å™¨
```

#### è§£å†³æ–¹æ¡ˆ

```python
env = make_vec_env(env_id, n_envs=4)

env = VecNormalize(env, norm_obs=True, norm_reward=True, clip_obs=10.)
```

### åˆ›å»ºA2Cæ¨¡å‹ ğŸ¤–

æœ‰å…³ä½¿ç”¨StableBaselines3å®ç°A2Cçš„æ›´å¤šä¿¡æ¯ï¼Œè¯·æŸ¥çœ‹ï¼šhttps://stable-baselines3.readthedocs.io/en/master/modules/a2c.html#notes

ä¸ºäº†æ‰¾åˆ°æœ€ä½³å‚æ•°ï¼Œæˆ‘æŸ¥çœ‹äº†[Stable-Baselines3å›¢é˜Ÿçš„å®˜æ–¹è®­ç»ƒæ™ºèƒ½ä½“](https://huggingface.co/sb3)ã€‚

```python
model = # åˆ›å»ºA2Cæ¨¡å‹å¹¶å°è¯•æ‰¾åˆ°æœ€ä½³å‚æ•°
```

#### è§£å†³æ–¹æ¡ˆ

```python
model = A2C(policy = "MultiInputPolicy",
            env = env,
            verbose=1)
```

### è®­ç»ƒA2Cæ™ºèƒ½ä½“ ğŸƒ

- è®©æˆ‘ä»¬è®­ç»ƒæˆ‘ä»¬çš„æ™ºèƒ½ä½“1,000,000ä¸ªæ—¶é—´æ­¥ï¼Œä¸è¦å¿˜è®°åœ¨Colabä¸Šä½¿ç”¨GPUã€‚è¿™å°†èŠ±è´¹å¤§çº¦~25-40åˆ†é’Ÿ

```python
model.learn(1_000_000)
```

```python
# ä¿å­˜æ¨¡å‹å’ŒVecNormalizeç»Ÿè®¡æ•°æ®
model.save("a2c-PandaReachDense-v3")
env.save("vec_normalize.pkl")
```

### è¯„ä¼°æ™ºèƒ½ä½“ ğŸ“ˆ

- ç°åœ¨æˆ‘ä»¬çš„æ™ºèƒ½ä½“å·²ç»è®­ç»ƒå¥½äº†ï¼Œæˆ‘ä»¬éœ€è¦**æ£€æŸ¥å®ƒçš„æ€§èƒ½**ã€‚
- Stable-Baselines3æä¾›äº†ä¸€ä¸ªæ–¹æ³•æ¥åšåˆ°è¿™ä¸€ç‚¹ï¼š`evaluate_policy`

```python
from stable_baselines3.common.vec_env import DummyVecEnv, VecNormalize

# åŠ è½½ä¿å­˜çš„ç»Ÿè®¡æ•°æ®
eval_env = DummyVecEnv([lambda: gym.make("PandaReachDense-v3")])
eval_env = VecNormalize.load("vec_normalize.pkl", eval_env)

# æˆ‘ä»¬éœ€è¦è¦†ç›–render_mode
eval_env.render_mode = "rgb_array"

# æµ‹è¯•æ—¶ä¸æ›´æ–°ç»Ÿè®¡æ•°æ®
eval_env.training = False
# æµ‹è¯•æ—¶ä¸éœ€è¦å¥–åŠ±æ ‡å‡†åŒ–
eval_env.norm_reward = False

# åŠ è½½æ™ºèƒ½ä½“
model = A2C.load("a2c-PandaReachDense-v3")

mean_reward, std_reward = evaluate_policy(model, eval_env)

print(f"å¹³å‡å¥–åŠ± = {mean_reward:.2f} +/- {std_reward:.2f}")
```
### åœ¨Hubä¸Šå‘å¸ƒä½ è®­ç»ƒçš„æ¨¡å‹ ğŸ”¥

ç°åœ¨æˆ‘ä»¬çœ‹åˆ°è®­ç»ƒåè·å¾—äº†è‰¯å¥½çš„ç»“æœï¼Œæˆ‘ä»¬å¯ä»¥ç”¨ä¸€è¡Œä»£ç å°†æˆ‘ä»¬è®­ç»ƒçš„æ¨¡å‹å‘å¸ƒåˆ°Hubä¸Šã€‚

ğŸ“š åº“æ–‡æ¡£ ğŸ‘‰ https://github.com/huggingface/huggingface_sb3/tree/main#hugging-face--x-stable-baselines3-v20

é€šè¿‡ä½¿ç”¨`package_to_hub`ï¼Œæ­£å¦‚æˆ‘ä»¬åœ¨å‰é¢çš„å•å…ƒä¸­å·²ç»æåˆ°çš„ï¼Œ**ä½ å¯ä»¥è¯„ä¼°ã€è®°å½•å›æ”¾ã€ç”Ÿæˆæ™ºèƒ½ä½“çš„æ¨¡å‹å¡ç‰‡å¹¶å°†å…¶æ¨é€åˆ°hub**ã€‚

è¿™æ ·ï¼š
- ä½ å¯ä»¥**å±•ç¤ºæˆ‘ä»¬çš„å·¥ä½œ** ğŸ”¥
- ä½ å¯ä»¥**å¯è§†åŒ–ä½ çš„æ™ºèƒ½ä½“çš„æ¸¸æˆè¿‡ç¨‹** ğŸ‘€
- ä½ å¯ä»¥**ä¸ç¤¾åŒºåˆ†äº«ä¸€ä¸ªå…¶ä»–äººå¯ä»¥ä½¿ç”¨çš„æ™ºèƒ½ä½“** ğŸ’¾
- ä½ å¯ä»¥**è®¿é—®æ’è¡Œæ¦œ ğŸ† æŸ¥çœ‹ä½ çš„æ™ºèƒ½ä½“ä¸åŒå­¦ç›¸æ¯”è¡¨ç°å¦‚ä½•** ğŸ‘‰ https://huggingface.co/spaces/huggingface-projects/Deep-Reinforcement-Learning-Leaderboard

è¦èƒ½å¤Ÿä¸ç¤¾åŒºåˆ†äº«ä½ çš„æ¨¡å‹ï¼Œè¿˜æœ‰ä¸‰ä¸ªæ­¥éª¤éœ€è¦éµå¾ªï¼š

1ï¸âƒ£ (å¦‚æœè¿˜æ²¡æœ‰å®Œæˆ)åœ¨HFåˆ›å»ºä¸€ä¸ªè´¦æˆ· â¡ https://huggingface.co/join

2ï¸âƒ£ ç™»å½•ï¼Œç„¶åï¼Œä½ éœ€è¦ä»Hugging Faceç½‘ç«™å­˜å‚¨ä½ çš„è®¤è¯ä»¤ç‰Œã€‚
- åˆ›å»ºä¸€ä¸ªæ–°ä»¤ç‰Œ(https://huggingface.co/settings/tokens) **å…·æœ‰å†™å…¥æƒé™**

<img src="https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/notebooks/create-token.jpg" alt="åˆ›å»ºHFä»¤ç‰Œ" />

- å¤åˆ¶ä»¤ç‰Œ
- è¿è¡Œä¸‹é¢çš„å•å…ƒæ ¼å¹¶ç²˜è´´ä»¤ç‰Œ

```python
notebook_login()
!git config --global credential.helper store
```
å¦‚æœä½ ä¸æƒ³ä½¿ç”¨Google Colabæˆ–Jupyter Notebookï¼Œä½ éœ€è¦ä½¿ç”¨è¿™ä¸ªå‘½ä»¤ä»£æ›¿ï¼š`huggingface-cli login`

3ï¸âƒ£ æˆ‘ä»¬ç°åœ¨å‡†å¤‡å¥½ä½¿ç”¨`package_to_hub()`å‡½æ•°å°†æˆ‘ä»¬è®­ç»ƒçš„æ™ºèƒ½ä½“æ¨é€åˆ°ğŸ¤— Hub ğŸ”¥ã€‚
å¯¹äºè¿™ä¸ªç¯å¢ƒï¼Œ**è¿è¡Œè¿™ä¸ªå•å…ƒæ ¼å¤§çº¦éœ€è¦10åˆ†é’Ÿ**

```python
from huggingface_sb3 import package_to_hub

package_to_hub(
    model=model,
    model_name=f"a2c-{env_id}",
    model_architecture="A2C",
    env_id=env_id,
    eval_env=eval_env,
    repo_id=f"ThomasSimonini/a2c-{env_id}", # æ›´æ”¹ç”¨æˆ·å
    commit_message="Initial commit",
)
```

## ä¸€äº›é¢å¤–çš„æŒ‘æˆ˜ ğŸ†

å­¦ä¹ çš„æœ€å¥½æ–¹æ³•**æ˜¯è‡ªå·±å°è¯•**ï¼ä¸ºä»€ä¹ˆä¸å°è¯•`PandaPickAndPlace-v3`ï¼Ÿ

å¦‚æœä½ æƒ³å°è¯•panda-gymçš„æ›´é«˜çº§ä»»åŠ¡ï¼Œä½ éœ€è¦æŸ¥çœ‹ä½¿ç”¨**TQCæˆ–SAC**ï¼ˆä¸€ç§æ›´é€‚åˆæœºå™¨äººä»»åŠ¡çš„æ ·æœ¬é«˜æ•ˆç®—æ³•ï¼‰æ‰€åšçš„å·¥ä½œã€‚åœ¨çœŸå®çš„æœºå™¨äººå­¦ä¸­ï¼Œä½ ä¼šä½¿ç”¨æ›´æ ·æœ¬é«˜æ•ˆçš„ç®—æ³•ï¼ŒåŸå› å¾ˆç®€å•ï¼šä¸æ¨¡æ‹Ÿç›¸åï¼Œ**å¦‚æœä½ è¿‡åº¦ç§»åŠ¨ä½ çš„æœºå™¨äººæ‰‹è‡‚ï¼Œä½ æœ‰å¯èƒ½ä¼šæŸåå®ƒ**ã€‚

PandaPickAndPlace-v1ï¼ˆè¿™ä¸ªæ¨¡å‹ä½¿ç”¨ç¯å¢ƒçš„v1ç‰ˆæœ¬ï¼‰ï¼šhttps://huggingface.co/sb3/tqc-PandaPickAndPlace-v1

ä¸è¦çŠ¹è±«ï¼Œåœ¨è¿™é‡ŒæŸ¥çœ‹panda-gymæ–‡æ¡£ï¼šhttps://panda-gym.readthedocs.io/en/latest/usage/train_with_sb3.html

æˆ‘ä»¬ä¸ºä½ æä¾›è®­ç»ƒå¦ä¸€ä¸ªæ™ºèƒ½ä½“çš„æ­¥éª¤ï¼ˆå¯é€‰ï¼‰ï¼š

1. å®šä¹‰åä¸º"PandaPickAndPlace-v3"çš„ç¯å¢ƒ
2. åˆ›å»ºå‘é‡åŒ–ç¯å¢ƒ
3. æ·»åŠ åŒ…è£…å™¨æ¥æ ‡å‡†åŒ–è§‚å¯Ÿå’Œå¥–åŠ±ã€‚[æŸ¥çœ‹æ–‡æ¡£](https://stable-baselines3.readthedocs.io/en/master/guide/vec_envs.html#vecnormalize)
4. åˆ›å»ºA2Cæ¨¡å‹ï¼ˆä¸è¦å¿˜è®°verbose=1æ¥æ‰“å°è®­ç»ƒæ—¥å¿—ï¼‰ã€‚
5. è®­ç»ƒ100ä¸‡ä¸ªæ—¶é—´æ­¥
6. ä¿å­˜æ¨¡å‹å’ŒVecNormalizeç»Ÿè®¡æ•°æ®
7. è¯„ä¼°ä½ çš„æ™ºèƒ½ä½“
8. ä½¿ç”¨`package_to_hub`åœ¨Hubä¸Šå‘å¸ƒä½ è®­ç»ƒçš„æ¨¡å‹ ğŸ”¥


### è§£å†³æ–¹æ¡ˆï¼ˆå¯é€‰ï¼‰

```python
# 1 - 2
env_id = "PandaPickAndPlace-v3"
env = make_vec_env(env_id, n_envs=4)

# 3
env = VecNormalize(env, norm_obs=True, norm_reward=True, clip_obs=10.)

# 4
model = A2C(policy = "MultiInputPolicy",
            env = env,
            verbose=1)
# 5
model.learn(1_000_000)
```

```python
# 6
model_name = "a2c-PandaPickAndPlace-v3";
model.save(model_name)
env.save("vec_normalize.pkl")

# 7
from stable_baselines3.common.vec_env import DummyVecEnv, VecNormalize

# åŠ è½½ä¿å­˜çš„ç»Ÿè®¡æ•°æ®
eval_env = DummyVecEnv([lambda: gym.make("PandaPickAndPlace-v3")])
eval_env = VecNormalize.load("vec_normalize.pkl", eval_env)

# æµ‹è¯•æ—¶ä¸æ›´æ–°ç»Ÿè®¡æ•°æ®
eval_env.training = False
# æµ‹è¯•æ—¶ä¸éœ€è¦å¥–åŠ±æ ‡å‡†åŒ–
eval_env.norm_reward = False

# åŠ è½½æ™ºèƒ½ä½“
model = A2C.load(model_name)

mean_reward, std_reward = evaluate_policy(model, eval_env)

print(f"å¹³å‡å¥–åŠ± = {mean_reward:.2f} +/- {std_reward:.2f}")

# 8
package_to_hub(
    model=model,
    model_name=f"a2c-{env_id}",
    model_architecture="A2C",
    env_id=env_id,
    eval_env=eval_env,
    repo_id=f"ThomasSimonini/a2c-{env_id}", # TODO: æ›´æ”¹ç”¨æˆ·å
    commit_message="Initial commit",
)
```

æˆ‘ä»¬åœ¨å•å…ƒ7è§ï¼ï¿½ï¿½

## æŒç»­å­¦ä¹ ï¼Œä¿æŒç²¾å½© ğŸ¤—
