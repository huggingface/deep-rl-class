# Monte Carlo Policy Gradient (Reinforce)



Now that we have seen the big picture of Policy-Gradient and its advantages and disadvantages, **let's study and implement one of them**: Reinforce.

## Reinforce (Monte Carlo Policy Gradient)

Reinforce, also called Monte-Carlo Policy Gradient, **uses an estimated return from an entire episode to update the policy parameter** \\(\theta\\).


Now that we studied the theory behind Reinforce, **youâ€™re ready to code your Reinforce agent with PyTorch**. And you'll test its robustness using CartPole-v1, PixelCopter, and Pong.

Start the tutorial here ğŸ‘‰ https://colab.research.google.com/github/huggingface/deep-rl-class/blob/main/unit5/unit5.ipynb

The leaderboard to compare your results with your classmates ğŸ† ğŸ‘‰ https://huggingface.co/spaces/chrisjay/Deep-Reinforcement-Learning-Leaderboard

<figure class="image table text-center m-0 w-full">
  <img src="https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit6/envs.gif" alt="Environments"/>
</figure>
---

Congrats on finishing this chapter!Â There was a lot of information. And congrats on finishing the tutorial. Youâ€™ve just coded your first Deep Reinforcement Learning agent from scratch using PyTorch and shared it on the Hub ğŸ¥³.

It'sÂ **normal if you still feel confused**Â with all these elements.Â **This was the same for me and for all people who studied RL.**

Take time to really grasp the material before continuing.

Don't hesitate to train your agent in other environments. TheÂ **best way to learn is to try things on your own!**

We published additional readings in the syllabus if you want to go deeper ğŸ‘‰Â **[https://github.com/huggingface/deep-rl-class/blob/main/unit5/README.md](https://github.com/huggingface/deep-rl-class/blob/main/unit5/README.md)**

In the next unit, weâ€™re going to learn about a combination of Policy-Based and value-based methods called Actor Critic Methods.

And don't forget to share with your friends who want to learn ğŸ¤—!

Finally, we wantÂ **to improve and update the course iteratively with your feedback**. If you have some, please fill this form ğŸ‘‰Â **[https://forms.gle/3HgA7bEHwAmmLfwh9](https://forms.gle/3HgA7bEHwAmmLfwh9)**

### **Keep learning, stay awesome ğŸ¤—,**
