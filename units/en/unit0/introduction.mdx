# Welcome to the ğŸ¤— Deep Reinforcement Learning Course [[introduction]]

<img src="https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit0/thumbnail.jpg" alt="Deep RL Course thumbnail" width="100%"/>

Welcome to the most fascinating topic in Artificial Intelligence:Â Deep Reinforcement Learning.

This course will **teach you about Deep Reinforcement Learning from beginner to expert**. Itâ€™s completely free and open-source!

In this introduction unit youâ€™ll:

- Learn more about the **course content**.
- **Define the path** youâ€™re going to take (either self-audit or certification process)
- Learn more about the **AI vs. AI challenges** you're going to participate to.
- Learn more **about us**.
- **Create your Hugging Face account** (itâ€™s free).
- **Sign-up our Discord server**, the place where you can exchange with your classmates and us (the Hugging Face team).

Letâ€™s get started!

## What to expect? [[expect]]

In this course, you will:

- ğŸ“– Study Deep Reinforcement Learning in **theory and practice.**
- ğŸ§‘â€ğŸ’» Learn to **use famous Deep RL libraries** such as [Stable Baselines3](https://stable-baselines3.readthedocs.io/en/master/), [RL Baselines3 Zoo](https://github.com/DLR-RM/rl-baselines3-zoo), [Sample Factory](https://samplefactory.dev/) and [CleanRL](https://github.com/vwxyzjn/cleanrl).
- ğŸ¤– **Train agents in unique environments** such as [SnowballFight](https://huggingface.co/spaces/ThomasSimonini/SnowballFight), [Huggy the Doggo ğŸ¶](https://huggingface.co/spaces/ThomasSimonini/Huggy), [MineRL (MinecraftÂ â›ï¸)](https://minerl.io/), [VizDoom (Doom)](https://vizdoom.cs.put.edu.pl/)Â and classical ones such as [Space Invaders](https://www.gymlibrary.dev/environments/atari/) and [PyBullet](https://pybullet.org/wordpress/).
- ğŸ’¾ Share your **trained agents with one line of code to the Hub** and also download powerful agents from the community.
- ğŸ† Participate in challenges where you will **evaluate your agents against other teams. You'll also get to play against the agents you'll train.**

And more!

At the end of this course, **youâ€™ll get a solid foundation from the basics to the SOTA (state-of-the-art) methods**.

You can find the syllabus on our website ğŸ‘‰ <a href="https://simoninithomas.github.io/deep-rl-course/">here</a>

Donâ€™t forget to **<a href="http://eepurl.com/ic5ZUD">sign up to the course</a>** (we are collecting your email to be able toÂ **send you the links when each Unit is published and give you information about the challenges and updates).**

Sign up  ğŸ‘‰ <a href="http://eepurl.com/ic5ZUD">here</a>


## What does the course look like? [[course-look-like]]
The course is composed of:

- *A theory part*: where you learn a **concept in theory (article)**.
- *A hands-on*: where youâ€™ll learn **to use famous Deep RL libraries** to train your agents in unique environments. These hands-on will be **Google Colab notebooks with companion tutorial videos** if you prefer learning with video format!
- *Challenges*: such AI vs. AI and leaderboard.


## Two paths: choose your own adventure [[two-paths]]

<img src="https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit0/two-paths.jpg" alt="Two paths" width="100%"/>

You can choose to follow this course either:

- *To get a certificate of completion*: you need to complete 80% of the assignments before the end of March 2023.
- *As a simple audit*: you can participate in all challenges and do assignments if you want, but you have no deadlines.

Whatever path you choose, we advise you **to follow the recommended pace to enjoy the course and challenges with your fellow classmates.**
You don't need to tell us which path you choose. At the end of March, when we verify the assignments **if you get more than 80% of the assignments done, you'll get a certificate.**



## How to get most of the course? [[advice]]

To get most of the course, we have some advice:

1. <a href="https://discord.gg/ydHrjt3WP5">Join or create study groups in Discord </a>: studying in groups is always easier. To do that, you need to join our discord server.
2. **Do the quizzes and assignments**: the best way to learn is to do and test yourself.
3. **Define a schedule to stay in sync**: you can use our recommended pace schedule below or create yours.

<img src="https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit0/advice.jpg" alt="Course advice" width="100%"/>

## What tools do I need? [[tools]]

You need only 3 things:

- *A computer* with an internet connection.
- *Google Colab (free version)*: most of our hands-on will use Google Colab, the **free version is enough.**
- A *Hugging Face Account*: to push and load models. If you donâ€™t have an account yet you can create one here (itâ€™s free).

<img src="https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit0/tools.jpg" alt="Course tools needed" width="100%"/>


## What is the recommended pace? [[recommended-pace]]

We defined a planning that you can follow to keep up the pace of the course.

<img src="https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit0/pace1.jpg" alt="Course advice" width="100%"/>
<img src="https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit0/pace2.jpg" alt="Course advice" width="100%"/>


Each chapter in this course is designed **to be completed in 1 week, with approximately 3-4 hours of work per week**. However, you can take as much time as you need to complete the course.


## Who are we [[who-are-we]]
About the author:

- <a href="https://twitter.com/ThomasSimonini">Thomas Simonini</a> is a Developer Advocate at Hugging Face ğŸ¤— specializing in Deep Reinforcement Learning. He founded Deep Reinforcement Learning Course in 2018, which became one of the most used courses in Deep RL.

About the reviewers:

- <a href="https://twitter.com/osanseviero">Omar Sanseviero</a> is a Machine Learning engineer at Hugging Face where he works in the intersection of ML, Community and Open Source. Previously, Omar worked as a Software Engineer at Google in the teams of Assistant and TensorFlow Graphics. He is from Peru and likes llamas ğŸ¦™.
- <a href="https://twitter.com/RisingSayak"> Sayak Paul</a> is a Developer Advocate Engineer at Hugging Face. He's interested in the area of representation learning (self-supervision, semi-supervision, model robustness). And he loves watching crime and action thrillers ğŸ”ª.


## When do the challenges start? [[challenges]]

In this new version of the course, you have two types of challenges:
- A leaderboard to compare your agent's performance to other classmates'.
- AI vs. AI challenges where you can train your agent and compete against other classmates' agents.

<img src="https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit0/challenges.jpg" alt="Challenges" width="100%"/>

These AI vs.AI challenges will be announced **later in December**.


## I found a bug, or I want to improve the course [[contribute]]

Contributions are welcomed ğŸ¤—

- If you *found a bug ğŸ› in a notebook*, please <a href="https://github.com/huggingface/deep-rl-class/issues">open an issue</a> and **describe the problem**.
- If you *want to improve the course*, you can <a href="https://github.com/huggingface/deep-rl-class/pulls">open a Pull Request.</a>

## I still have questions [[questions]]

In that case, <a href="https://simoninithomas.github.io/deep-rl-course/#faq">check our FAQ</a>. And if the question is not in it, ask your question in our <a href="https://discord.gg/ydHrjt3WP5">discord server #rl-discussions.</a>
