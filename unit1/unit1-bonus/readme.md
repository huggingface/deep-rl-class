# Unit 1: Bonus ğŸ
- Our teammate @Chris Emezue published a new leaderboard where you can compare your trained agents in new environments ğŸ‘‰  https://huggingface.co/spaces/chrisjay/Deep-Reinforcement-Learning-Leaderboard

## Try new environments ğŸ®
Now that you've played with LunarLander-v2 Why not try these environments? ğŸ”¥:
- ğŸ—» MountainCar-v0  https://www.gymlibrary.dev/environments/classic_control/mountain_car/
- ğŸï¸ CarRacing-v1 https://www.gymlibrary.dev/environments/box2d/car_racing/
- ğŸ¥¶ FrozenLake-v1 https://www.gymlibrary.dev/environments/toy_text/frozen_lake/
 
## A piece of advice ğŸ§
The first Unit, is a very interesting one but also **a very complex one  because it's where you learn the fundamentals.**

Thatâ€™s normal if you **still feel confused with all these elements**. This was the same for me and for all people who studied RL.

Take time to really grasp the material before continuing. Itâ€™s important to master these elements and having a solid foundations before entering the fun part.

We published additional readings in the syllabus if you want to go deeper ğŸ‘‰ https://github.com/huggingface/deep-rl-class/blob/main/unit1/README.md

The hands-on for the first Unit are more funny experiments, but as we'll go deeper, **you'll understand better how to choose the hyperparameters and what model to use. For now, have fun, try stuff you can't break the simulations  ğŸš€ **

### Keep learning, stay awesome. 
